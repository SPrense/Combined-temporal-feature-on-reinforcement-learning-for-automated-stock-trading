{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yfv52r2G33jY"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/AI4Finance-Foundation/FinRL/blob/master/Stock_NeurIPS2018.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gXaoZs2lh1hi"
   },
   "source": [
    "# Deep Reinforcement Learning for Stock Trading from Scratch: Multiple Stock Trading\n",
    "\n",
    "* **Pytorch Version** \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lGunVt8oLCVS"
   },
   "source": [
    "# Content"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HOzAKQ-SLGX6"
   },
   "source": [
    "* [1. Task Description](#0)\n",
    "* [2. Install Python packages](#1)\n",
    "    * [2.1. Install Packages](#1.1)    \n",
    "    * [2.2. A List of Python Packages](#1.2)\n",
    "    * [2.3. Import Packages](#1.3)\n",
    "    * [2.4. Create Folders](#1.4)\n",
    "* [3. Download and Preprocess Data](#2)\n",
    "* [4. Preprocess Data](#3)        \n",
    "    * [4.1. Technical Indicators](#3.1)\n",
    "    * [4.2. Perform Feature Engineering](#3.2)\n",
    "* [5. Build Market Environment in OpenAI Gym-style](#4)  \n",
    "    * [5.1. Data Split](#4.1)  \n",
    "    * [5.3. Environment for Training](#4.2)    \n",
    "* [6. Train DRL Agents](#5)\n",
    "* [7. Backtesting Performance](#6)  \n",
    "    * [7.1. BackTestStats](#6.1)\n",
    "    * [7.2. BackTestPlot](#6.2)   \n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sApkDlD9LIZv"
   },
   "source": [
    "<a id='0'></a>\n",
    "# Part 1. Task Discription"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HjLD2TZSLKZ-"
   },
   "source": [
    "We train a DRL agent for stock trading. This task is modeled as a Markov Decision Process (MDP), and the objective function is maximizing (expected) cumulative return.\n",
    "\n",
    "We specify the state-action-reward as follows:\n",
    "\n",
    "* **State s**: The state space represents an agent's perception of the market environment. Just like a human trader analyzing various information, here our agent passively observes many features and learns by interacting with the market environment (usually by replaying historical data).\n",
    "\n",
    "* **Action a**: The action space includes allowed actions that an agent can take at each state. For example, a ∈ {−1, 0, 1}, where −1, 0, 1 represent\n",
    "selling, holding, and buying. When an action operates multiple shares, a ∈{−k, ..., −1, 0, 1, ..., k}, e.g.. \"Buy\n",
    "10 shares of AAPL\" or \"Sell 10 shares of AAPL\" are 10 or −10, respectively\n",
    "\n",
    "* **Reward function r(s, a, s′)**: Reward is an incentive for an agent to learn a better policy. For example, it can be the change of the portfolio value when taking a at state s and arriving at new state s',  i.e., r(s, a, s′) = v′ − v, where v′ and v represent the portfolio values at state s′ and s, respectively\n",
    "\n",
    "\n",
    "**Market environment**: 30 consituent stocks of Dow Jones Industrial Average (DJIA) index. Accessed at the starting date of the testing period.\n",
    "\n",
    "\n",
    "The data for this case study is obtained from Yahoo Finance API. The data contains Open-High-Low-Close price and volume.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ffsre789LY08"
   },
   "source": [
    "<a id='1'></a>\n",
    "# Part 2. Install Python Packages"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Uy5_PTmOh1hj"
   },
   "source": [
    "<a id='1.1'></a>\n",
    "## 2.1. Install packages\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install Ta-Lib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install Ta-Lib -i https://pypi.tuna.tsinghua.edu.cn/simple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install git+https://github.com/quantopian/pyfolio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "mPT0ipYE28wL",
    "outputId": "02a8a804-d120-4388-a167-20a81cb33d87"
   },
   "outputs": [],
   "source": [
    "## install finrl library\n",
    "!pip install wrds -i https://pypi.tuna.tsinghua.edu.cn/simple\n",
    "!pip install swig -i https://pypi.tuna.tsinghua.edu.cn/simple\n",
    "!pip install git+https://github.com/AI4Finance-Foundation/FinRL.git "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "osBHhVysOEzi"
   },
   "source": [
    "\n",
    "<a id='1.2'></a>\n",
    "## 2.2. A list of Python packages \n",
    "* Yahoo Finance API\n",
    "* pandas\n",
    "* numpy\n",
    "* matplotlib\n",
    "* stockstats\n",
    "* OpenAI gym\n",
    "* stable-baselines\n",
    "* tensorflow\n",
    "* pyfolio"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nGv01K8Sh1hn"
   },
   "source": [
    "<a id='1.3'></a>\n",
    "## 2.3. Import Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "lPqeTTwoh1hn"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import datetime\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import statsmodels.tsa.stattools as ts\n",
    "# matplotlib.use('Agg')\n",
    "from torch import nn\n",
    "from torch import optim\n",
    "from torch.nn import functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "\n",
    "%matplotlib inline\n",
    "#from finrl.meta.preprocessor.yahoodownloader import YahooDownloader\n",
    "from finrl.meta.preprocessor.preprocessors import FeatureEngineer, data_split\n",
    "from finrl.meta.env_stock_trading.env_stocktrading_adjust import StockTradingEnv\n",
    "from finrl.agents.stablebaselines3.models_add import DRLAgent\n",
    "from stable_baselines3.common.logger import configure\n",
    "from finrl.meta.data_processor import DataProcessor\n",
    "\n",
    "from finrl.plot import backtest_stats, backtest_plot, get_daily_return, get_baseline\n",
    "from pprint import pprint\n",
    "\n",
    "import sys\n",
    "sys.path.append(\"../mha-gru-drl\")\n",
    "\n",
    "import itertools"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "T2owTj985RW4"
   },
   "source": [
    "<a id='1.4'></a>\n",
    "## 2.4. Create Folders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "RtUc_ofKmpdy"
   },
   "outputs": [],
   "source": [
    "from finrl import config\n",
    "from finrl import config_tickers\n",
    "import os\n",
    "from finrl.main import check_and_make_directories\n",
    "from finrl.config import (\n",
    "    DATA_SAVE_DIR,\n",
    "    TRAINED_MODEL_DIR,\n",
    "    TENSORBOARD_LOG_DIR,\n",
    "    RESULTS_DIR,\n",
    "    INDICATORS,\n",
    "    TRAIN_START_DATE,\n",
    "    TRAIN_END_DATE,\n",
    "    TEST_START_DATE,\n",
    "    TEST_END_DATE,\n",
    "    TRADE_START_DATE,\n",
    "    TRADE_END_DATE,\n",
    ")\n",
    "check_and_make_directories([DATA_SAVE_DIR, TRAINED_MODEL_DIR, TENSORBOARD_LOG_DIR, RESULTS_DIR])\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "A289rQWMh1hq"
   },
   "source": [
    "<a id='2'></a>\n",
    "# Part 3. Download Data\n",
    "Yahoo Finance provides stock data, financial news, financial reports, etc. Yahoo Finance is free.\n",
    "* FinRL uses a class **YahooDownloader** in FinRL-Meta to fetch data via Yahoo Finance API\n",
    "* Call Limit: Using the Public API (without authentication), you are limited to 2,000 requests per hour per IP (or up to a total of 48,000 requests a day)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NPeQ7iS-LoMm"
   },
   "source": [
    "\n",
    "\n",
    "-----\n",
    "class YahooDownloader:\n",
    "    Retrieving daily stock data from\n",
    "    Yahoo Finance API\n",
    "\n",
    "    Attributes\n",
    "    ----------\n",
    "        start_date : str\n",
    "            start date of the data (modified from config.py)\n",
    "        end_date : str\n",
    "            end date of the data (modified from config.py)\n",
    "        ticker_list : list\n",
    "            a list of stock tickers (modified from config.py)\n",
    "\n",
    "    Methods\n",
    "    -------\n",
    "    fetch_data()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "h3XJnvrbLp-C",
    "outputId": "3c4dda81-f617-4e9b-f88c-edb502d1500c"
   },
   "outputs": [],
   "source": [
    "# from config.py, TRAIN_START_DATE is a string\n",
    "TRAIN_START_DATE\n",
    "# from config.py, TRAIN_END_DATE is a string\n",
    "TRAIN_END_DATE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "FUnY8WEfLq3C"
   },
   "outputs": [],
   "source": [
    "TRAIN_START_DATE = '2017-03-02'\n",
    "TRAIN_END_DATE = '2020-02-27'\n",
    "TRADE_START_DATE = '2020-02-28'\n",
    "TRADE_END_DATE = '2023-12-01'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tushare as ts\n",
    "ts.set_token('df3c6a8e252ff736ca08a3364022e4340b68485bf9f9d3cea4c94f21')\n",
    "pro = ts.pro_api()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#选择上证50指数的成分股\n",
    "df_index = pro.index_weight(index_code='000016.sh', start_date='20121010', end_date='20220228')\n",
    "# df_index.to_csv('SSE_50_index_weight.csv',index=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['601318.SH' '600016.SH' '601166.SH' '600000.SH' '600036.SH' '601328.SH'\n",
      " '601288.SH' '600030.SH' '600519.SH' '600837.SH' '601169.SH' '601398.SH'\n",
      " '601766.SH' '600887.SH' '601668.SH' '601601.SH' '601988.SH' '600104.SH'\n",
      " '600048.SH' '601818.SH' '601989.SH' '600015.SH' '600028.SH' '600637.SH'\n",
      " '601688.SH' '601390.SH' '600999.SH' '600518.SH' '601006.SH' '601857.SH'\n",
      " '600050.SH' '601186.SH' '601628.SH' '601985.SH' '600795.SH' '600585.SH'\n",
      " '600893.SH' '601088.SH' '600010.SH' '601901.SH' '601211.SH' '601669.SH'\n",
      " '600111.SH' '601336.SH' '600109.SH' '600958.SH' '601998.SH' '601800.SH'\n",
      " '600018.SH' '600150.SH'] 50\n"
     ]
    }
   ],
   "source": [
    "#选择某个时间点的上证50指数成分股作为参考跟踪股票池\n",
    "select_date = '20160229' #自定义的时间点为每个月的月末\n",
    "df_select = df_index[df_index['trade_date']==select_date]\n",
    "sort_SSEindex = df_select['con_code'].unique()\n",
    "print(sort_SSEindex,len(sort_SSEindex))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['601328.SH', '600109.SH', '601998.SH', '600111.SH', '600050.SH', '601169.SH', '600887.SH', '600795.SH', '601336.SH', '601818.SH', '601390.SH', '601688.SH', '600016.SH', '601800.SH', '600958.SH', '601166.SH', '600015.SH', '600010.SH', '600104.SH', '600150.SH', '601985.SH', '600028.SH', '600030.SH', '601186.SH', '600999.SH', '600585.SH', '601601.SH', '600036.SH', '601288.SH', '601006.SH', '601901.SH', '601989.SH', '601857.SH', '601668.SH', '600048.SH', '601988.SH', '600518.SH', '601628.SH', '601318.SH', '600018.SH', '601398.SH', '600000.SH', '601669.SH', '601211.SH', '600637.SH', '601088.SH', '600837.SH', '600893.SH', '601766.SH', '600519.SH']\n"
     ]
    }
   ],
   "source": [
    "#随机选择成分股中的k只股票\n",
    "import random \n",
    "k = 50\n",
    "selected_tics = random.sample(list(sort_SSEindex),k)\n",
    "print(selected_tics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "selected_tics = ['600104.SH','600050.SH','600048.SH','600036.SH','600031.SH','600030.SH','600028.SH','600016.SH','600009.SH','600000.SH']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        ts_code trade_date    open    high     low   close  pre_close  change  \\\n",
      "0     601328.SH   20221230    4.73    4.76    4.72    4.74       4.71    0.03   \n",
      "1     601328.SH   20221229    4.74    4.76    4.70    4.71       4.75   -0.04   \n",
      "2     601328.SH   20221228    4.71    4.75    4.70    4.75       4.71    0.04   \n",
      "3     601328.SH   20221227    4.66    4.73    4.66    4.71       4.65    0.06   \n",
      "4     601328.SH   20221226    4.68    4.69    4.64    4.65       4.68   -0.03   \n",
      "...         ...        ...     ...     ...     ...     ...        ...     ...   \n",
      "1454  600519.SH   20170109  347.80  352.88  346.54  348.51     350.76   -2.25   \n",
      "1455  600519.SH   20170106  346.64  359.78  346.10  350.76     346.74    4.02   \n",
      "1456  600519.SH   20170105  350.00  351.45  345.44  346.74     351.91   -5.17   \n",
      "1457  600519.SH   20170104  334.62  352.17  334.60  351.91     334.56   17.35   \n",
      "1458  600519.SH   20170103  334.28  337.00  332.81  334.56     334.15    0.41   \n",
      "\n",
      "      pct_chg        vol       amount  \n",
      "0      0.6369  792200.24   375783.188  \n",
      "1     -0.8421  763819.88   360486.613  \n",
      "2      0.8493  563854.00   267143.568  \n",
      "3      1.2903  570109.55   267762.951  \n",
      "4     -0.6410  622137.27   290093.044  \n",
      "...       ...        ...          ...  \n",
      "1454  -0.6400   35405.00  1233977.973  \n",
      "1455   1.1600   68095.62  2402546.296  \n",
      "1456  -1.4700   41704.48  1449077.676  \n",
      "1457   5.1900   65257.38  2245051.865  \n",
      "1458   0.1200   20763.89   695005.298  \n",
      "\n",
      "[72281 rows x 11 columns]\n"
     ]
    }
   ],
   "source": [
    "#Download随机选择的k只股票数据\n",
    "df_ts =pd.DataFrame()\n",
    "for c in selected_tics:\n",
    "    temp=pro.daily(ts_code=c,start_date=TRAIN_START_DATE,end_date=TRADE_END_DATE)\n",
    "    df_ts=pd.concat([df_ts,temp])\n",
    "print(df_ts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ts = pd.read_csv('10_test_628.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ts.to_csv('10_test_628.csv',index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_len = max(df_ts['ts_code'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def processed_date_range(df,selected_tics,k):\n",
    "    longth = []\n",
    "    tic_list = []\n",
    "    for tic in selected_tics:\n",
    "        temp_df = df[df['ts_code'] == tic]\n",
    "        temp_long = temp_df['trade_date'].iloc[-1]\n",
    "        longth.append(temp_long)\n",
    "        tic_list.append(tic)\n",
    "#         print(tic_list,longth)\n",
    "    minlong = max(longth)\n",
    "    date_unique = [date for date in df['trade_date'].unique() if date >= minlong]\n",
    "    full_date_range = pd.DataFrame(date_unique,columns=['trade_date'])\n",
    "    \n",
    "    return full_date_range\n",
    "#     date_unique = df['trade_date'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "k=50\n",
    "full_date_range = processed_date_range(df_ts,selected_tics,k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>trade_date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>20221230</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20221229</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>20221228</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>20221227</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20221226</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1454</th>\n",
       "      <td>20170109</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1455</th>\n",
       "      <td>20170106</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1456</th>\n",
       "      <td>20170105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1457</th>\n",
       "      <td>20170104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1458</th>\n",
       "      <td>20170103</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1459 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     trade_date\n",
       "0      20221230\n",
       "1      20221229\n",
       "2      20221228\n",
       "3      20221227\n",
       "4      20221226\n",
       "...         ...\n",
       "1454   20170109\n",
       "1455   20170106\n",
       "1456   20170105\n",
       "1457   20170104\n",
       "1458   20170103\n",
       "\n",
       "[1459 rows x 1 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_date_range"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "669\n",
      "         ts_code trade_date     open     high      low    close  pre_close  \\\n",
      "0      601328.SH   20170103     5.75     5.83     5.75     5.81       5.77   \n",
      "1      601328.SH   20170104     5.80     5.85     5.78     5.82       5.81   \n",
      "2      601328.SH   20170105     5.82     5.83     5.79     5.80       5.82   \n",
      "3      601328.SH   20170106     5.80     5.80     5.76     5.78       5.80   \n",
      "4      601328.SH   20170109     5.79     5.81     5.77     5.79       5.78   \n",
      "...          ...        ...      ...      ...      ...      ...        ...   \n",
      "72945  600519.SH   20221226  1771.00  1771.00  1735.02  1742.06    1771.00   \n",
      "72946  600519.SH   20221227  1738.00  1747.15  1725.50  1733.00    1720.15   \n",
      "72947  600519.SH   20221228  1745.88  1747.00  1708.01  1733.00    1733.00   \n",
      "72948  600519.SH   20221229  1717.00  1726.99  1701.05  1719.00    1733.00   \n",
      "72949  600519.SH   20221230  1736.00  1752.99  1727.00  1727.00    1719.00   \n",
      "\n",
      "       change  pct_chg         vol       amount  filled  \n",
      "0        0.04   0.6900   943101.92   545967.084       0  \n",
      "1        0.01   0.1700  1006829.09   585133.552       0  \n",
      "2       -0.02  -0.3400   550404.86   319892.025       0  \n",
      "3       -0.02  -0.3400   687547.96   397269.908       0  \n",
      "4        0.01   0.1700   470794.35   272693.519       0  \n",
      "...       ...      ...         ...          ...     ...  \n",
      "72945  -28.94  -1.6341    21383.80  3749121.030       0  \n",
      "72946   12.85   0.7470    17905.05  3109270.166       0  \n",
      "72947    0.00   0.0000    21437.90  3699948.995       0  \n",
      "72948  -14.00  -0.8078    22417.80  3844499.655       0  \n",
      "72949    8.00   0.4654    25333.12  4409544.297       0  \n",
      "\n",
      "[72950 rows x 12 columns]\n"
     ]
    }
   ],
   "source": [
    "#遍历扩充股票的完整交易日期\n",
    "def add_exchange_calendars(df,full_date_range,selected_tics):\n",
    "    count = 0\n",
    "    merge_df = []\n",
    "    for tic in selected_tics:\n",
    "        temp_df = df[df['ts_code'] == tic]\n",
    "        temp_full_date_range = full_date_range\n",
    "        temp_df = temp_df.set_index('trade_date')\n",
    "        temp_full_date_range = temp_full_date_range.set_index('trade_date')\n",
    "        temp_df = pd.merge(temp_full_date_range,temp_df,how='left',left_index=True,right_index=True)\n",
    "        temp_df = temp_df.reset_index().sort_values('trade_date',ascending=True)\n",
    "        temp_df = temp_df.fillna({\n",
    "            'amount' : 0,\n",
    "            'vol': 0,\n",
    "            'pct_chg': 0,\n",
    "            'change':0,\n",
    "            'ts_code': tic\n",
    "        })\n",
    "        temp_df['filled'] = temp_df['close'].isna().astype(int)\n",
    "#         print(temp_df,temp_df['filled'].unique())\n",
    "        \n",
    "        for i in range(len(temp_df)):\n",
    "            if pd.isna(temp_df.loc[i,'close']):\n",
    "                j = i -1\n",
    "                while pd.isna(temp_df.loc[j,'close']):\n",
    "                    j = j - 1\n",
    "                if j > 0 :\n",
    "                    temp_df.loc[i,['close','open','high','low','pre_close']] = temp_df.loc[j,'close']\n",
    "                    count+=1\n",
    "        merge_df.append(temp_df)\n",
    "    merged_df = pd.concat(merge_df,ignore_index = True)\n",
    "    print(count)\n",
    "    return merged_df\n",
    "\n",
    "merged_df =  add_exchange_calendars(df_ts, full_date_range, selected_tics)\n",
    "# merged_df = merged_df.rename(columns={'trade_date':'date','ts_code':'tic','vol':'volume'})\n",
    "merged_df = merged_df[['ts_code','trade_date','open','high','low','close','pre_close','change','pct_chg','vol','amount','filled']]\n",
    "print(merged_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import talib as ta\n",
    "merged_df['ema'] = ta.EMA(merged_df[\"close\"], timeperiod=30)\n",
    "merged_df = merged_df.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df.to_csv('1230_merged_ema.csv',index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_df = merged_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ts_code</th>\n",
       "      <th>trade_date</th>\n",
       "      <th>open</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>close</th>\n",
       "      <th>pre_close</th>\n",
       "      <th>change</th>\n",
       "      <th>pct_chg</th>\n",
       "      <th>vol</th>\n",
       "      <th>amount</th>\n",
       "      <th>filled</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>600000.SH</td>\n",
       "      <td>2017-01-03</td>\n",
       "      <td>16.21</td>\n",
       "      <td>16.44</td>\n",
       "      <td>16.17</td>\n",
       "      <td>16.30</td>\n",
       "      <td>16.21</td>\n",
       "      <td>0.09</td>\n",
       "      <td>0.5600</td>\n",
       "      <td>162371.25</td>\n",
       "      <td>265043.268</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>600000.SH</td>\n",
       "      <td>2017-01-04</td>\n",
       "      <td>16.29</td>\n",
       "      <td>16.35</td>\n",
       "      <td>16.18</td>\n",
       "      <td>16.33</td>\n",
       "      <td>16.30</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.1800</td>\n",
       "      <td>296587.34</td>\n",
       "      <td>482612.222</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>600000.SH</td>\n",
       "      <td>2017-01-05</td>\n",
       "      <td>16.30</td>\n",
       "      <td>16.38</td>\n",
       "      <td>16.24</td>\n",
       "      <td>16.30</td>\n",
       "      <td>16.33</td>\n",
       "      <td>-0.03</td>\n",
       "      <td>-0.1800</td>\n",
       "      <td>264376.46</td>\n",
       "      <td>431449.126</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>600000.SH</td>\n",
       "      <td>2017-01-06</td>\n",
       "      <td>16.30</td>\n",
       "      <td>16.30</td>\n",
       "      <td>16.13</td>\n",
       "      <td>16.18</td>\n",
       "      <td>16.30</td>\n",
       "      <td>-0.12</td>\n",
       "      <td>-0.7400</td>\n",
       "      <td>171955.98</td>\n",
       "      <td>278864.536</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>600000.SH</td>\n",
       "      <td>2017-01-09</td>\n",
       "      <td>16.24</td>\n",
       "      <td>16.29</td>\n",
       "      <td>16.13</td>\n",
       "      <td>16.20</td>\n",
       "      <td>16.18</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.1200</td>\n",
       "      <td>149087.45</td>\n",
       "      <td>241579.598</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72945</th>\n",
       "      <td>601998.SH</td>\n",
       "      <td>2022-12-26</td>\n",
       "      <td>4.90</td>\n",
       "      <td>4.91</td>\n",
       "      <td>4.83</td>\n",
       "      <td>4.83</td>\n",
       "      <td>4.88</td>\n",
       "      <td>-0.05</td>\n",
       "      <td>-1.0246</td>\n",
       "      <td>189583.31</td>\n",
       "      <td>92209.197</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72946</th>\n",
       "      <td>601998.SH</td>\n",
       "      <td>2022-12-27</td>\n",
       "      <td>4.89</td>\n",
       "      <td>4.93</td>\n",
       "      <td>4.86</td>\n",
       "      <td>4.90</td>\n",
       "      <td>4.83</td>\n",
       "      <td>0.07</td>\n",
       "      <td>1.4493</td>\n",
       "      <td>170230.99</td>\n",
       "      <td>83528.189</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72947</th>\n",
       "      <td>601998.SH</td>\n",
       "      <td>2022-12-28</td>\n",
       "      <td>4.91</td>\n",
       "      <td>5.02</td>\n",
       "      <td>4.87</td>\n",
       "      <td>4.98</td>\n",
       "      <td>4.90</td>\n",
       "      <td>0.08</td>\n",
       "      <td>1.6327</td>\n",
       "      <td>209360.59</td>\n",
       "      <td>103967.749</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72948</th>\n",
       "      <td>601998.SH</td>\n",
       "      <td>2022-12-29</td>\n",
       "      <td>4.95</td>\n",
       "      <td>4.96</td>\n",
       "      <td>4.84</td>\n",
       "      <td>4.93</td>\n",
       "      <td>4.98</td>\n",
       "      <td>-0.05</td>\n",
       "      <td>-1.0040</td>\n",
       "      <td>260632.34</td>\n",
       "      <td>127533.792</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72949</th>\n",
       "      <td>601998.SH</td>\n",
       "      <td>2022-12-30</td>\n",
       "      <td>4.94</td>\n",
       "      <td>5.02</td>\n",
       "      <td>4.93</td>\n",
       "      <td>4.98</td>\n",
       "      <td>4.93</td>\n",
       "      <td>0.05</td>\n",
       "      <td>1.0142</td>\n",
       "      <td>216134.46</td>\n",
       "      <td>107621.813</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>72950 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         ts_code trade_date   open   high    low  close  pre_close  change  \\\n",
       "0      600000.SH 2017-01-03  16.21  16.44  16.17  16.30      16.21    0.09   \n",
       "1      600000.SH 2017-01-04  16.29  16.35  16.18  16.33      16.30    0.03   \n",
       "2      600000.SH 2017-01-05  16.30  16.38  16.24  16.30      16.33   -0.03   \n",
       "3      600000.SH 2017-01-06  16.30  16.30  16.13  16.18      16.30   -0.12   \n",
       "4      600000.SH 2017-01-09  16.24  16.29  16.13  16.20      16.18    0.02   \n",
       "...          ...        ...    ...    ...    ...    ...        ...     ...   \n",
       "72945  601998.SH 2022-12-26   4.90   4.91   4.83   4.83       4.88   -0.05   \n",
       "72946  601998.SH 2022-12-27   4.89   4.93   4.86   4.90       4.83    0.07   \n",
       "72947  601998.SH 2022-12-28   4.91   5.02   4.87   4.98       4.90    0.08   \n",
       "72948  601998.SH 2022-12-29   4.95   4.96   4.84   4.93       4.98   -0.05   \n",
       "72949  601998.SH 2022-12-30   4.94   5.02   4.93   4.98       4.93    0.05   \n",
       "\n",
       "       pct_chg        vol      amount  filled  \n",
       "0       0.5600  162371.25  265043.268       0  \n",
       "1       0.1800  296587.34  482612.222       0  \n",
       "2      -0.1800  264376.46  431449.126       0  \n",
       "3      -0.7400  171955.98  278864.536       0  \n",
       "4       0.1200  149087.45  241579.598       0  \n",
       "...        ...        ...         ...     ...  \n",
       "72945  -1.0246  189583.31   92209.197       0  \n",
       "72946   1.4493  170230.99   83528.189       0  \n",
       "72947   1.6327  209360.59  103967.749       0  \n",
       "72948  -1.0040  260632.34  127533.792       0  \n",
       "72949   1.0142  216134.46  107621.813       0  \n",
       "\n",
       "[72950 rows x 12 columns]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "processed_df1 = processed_df\n",
    "processed_df1 = processed_df1.sort_values(['ts_code','trade_date'],ascending=True,ignore_index=True)\n",
    "processed_df1['trade_date'] = pd.to_datetime(processed_df1['trade_date'])\n",
    "processed_df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #检验50只股票的信息缺省的时间点和个数\n",
    "# dimatch_num = 0\n",
    "# dimatch_date =[]\n",
    "# for c in df_ts1['trade_date'].unique():\n",
    "#     temp = df_ts1[df_ts1['trade_date'] == c]\n",
    "#     if len(temp) != 50:\n",
    "#         dimatch_num +=1\n",
    "#         dimatch_date.append(c)\n",
    "# print(dimatch_num,dimatch_date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(full_date_range)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# date_unique = df['date'].unique()\n",
    "# date_sum = len(date_unique)\n",
    "# count = 0\n",
    "# for date in date_unique:\n",
    "#     temp_df = df[df['trade_date'] == date]\n",
    "# #     if len(temp_df) = k:\n",
    "# #         count +=1\n",
    "# #     elif len(temp_df) < int(0.9*k):\n",
    "# #         date_unique.remove(date)\n",
    "# #     else:\n",
    "#     difference_tic = temp_df['ts_code'].tolist().difference(selected_tics)\n",
    "#     missing_tic.append(date,difference_tic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #遍历扩充股票的完整交易日期\n",
    "# def add_exchange_calendars(df,full_date_range,selected_tics):\n",
    "#     merge_df = []\n",
    "#     for tic in selected_tics:\n",
    "#         temp_df = df[df['ts_code'] == tic]\n",
    "#         temp_full_date_range = full_date_range\n",
    "#         temp_df = temp_df.set_index('trade_date')\n",
    "#         temp_full_date_range = temp_full_date_range.set_index('trade_date')\n",
    "#         temp_df = pd.merge(temp_full_date_range,temp_df,how='left',left_index=True,right_index=True)\n",
    "#         temp_df = temp_df.reset_index().sort_values('trade_date',ascending=True)\n",
    "#         temp_df = temp_df.fillna({\n",
    "#             'amount' : 0,\n",
    "#             'vol': 0,\n",
    "#             'pct_chg': 0,\n",
    "#             'change':0,\n",
    "#             'ts_code': tic\n",
    "#         })\n",
    "#         for i in range(len(temp_df)):\n",
    "#             if pd.isna(temp_df.loc[i,'close']):\n",
    "#                 j = i -1\n",
    "#                 while pd.isna(temp_df.loc[j,'close']):\n",
    "#                     j = j - 1\n",
    "#                 if j > 0 :\n",
    "#                     temp_df.loc[i,['close','open','high','low','pre_close']] = temp_df.loc[j,'close']\n",
    "#         merge_df.append(temp_df)\n",
    "#     merged_df = pd.concat(merge_df,ignore_index = True)\n",
    "#     return merged_df\n",
    "\n",
    "# merged_df =  add_exchange_calendars(df_ts,full_date_range,selected_tics)\n",
    "# merged_df = merged_df.rename(columns={'trade_date':'date','ts_code':'tic','vol':'volume'})\n",
    "# merged_df = merged_df[['tic','date','open','high','low','close','pre_close','change','pct_chg','volume','amount']]\n",
    "# print(merged_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 筛选exchange_calender中每个交易节点缺失情况\n",
    "# def processed_date(df,selected_tics,k):\n",
    "#     date_unique = list(df['trade_date'].unique())\n",
    "#     date_sum = len(date_unique)\n",
    "#     count = 0\n",
    "#     processe_df =[]\n",
    "#     processed_df = pd.DataFrame()\n",
    "#     for date in date_unique:\n",
    "#         temp_df = df[df['trade_date'] == date]\n",
    "#         if len(temp_df) < int(0.9*k):\n",
    "#             date_unique.remove(date)\n",
    "#         elif len(temp_df) >= int(0.9*k) and len(temp_df) < k:\n",
    "#             missing_tic = set(selected_tics).difference(set(temp_df['ts_code'].tolist()))\n",
    "# #             print(missing_tic)\n",
    "#             for m_tic in missing_tic:\n",
    "#                 temp_dict = {'ts_code':m_tic,'trade_date':date,'open':np.nan, 'high':np.nan,'low':np.nan, 'close':np.nan, 'pre_close':np.nan, 'change':np.nan, 'pct_chg':np.nan, 'volume':np.nan, 'amount':np.nan}\n",
    "#                 new_data = pd.DataFrame.from_dict(temp_dict,orient='index').T\n",
    "#                 temp_df = temp_df.append(new_data)\n",
    "# #             print(len(temp_df))\n",
    "#             processe_df.append(temp_df)\n",
    "#         else :\n",
    "#             count += 1\n",
    "#             processe_df.append(temp_df)\n",
    "#         processed_df = pd.concat(processe_df,ignore_index = True)       \n",
    "#     processed_df = processed_df.sort_values('trade_date',ascending=True).reset_index()\n",
    "#     processed_df = processed_df.drop('index',axis=1)\n",
    "#     return processed_df,date_unique\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 筛选exchange_calender中每个交易节点缺失情况(全部补充0)\n",
    "# def processed_date(df,selected_tics,k):\n",
    "#     date_unique = list(df['trade_date'].unique())\n",
    "#     date_sum = len(date_unique)\n",
    "#     count = 0\n",
    "#     processe_df =[]\n",
    "#     processed_df = pd.DataFrame()\n",
    "#     for date in date_unique:\n",
    "#         temp_df = df[df['trade_date'] == date]\n",
    "#         if len(temp_df) != k:\n",
    "#             missing_tic = set(selected_tics).difference(set(temp_df['ts_code'].tolist()))\n",
    "# #             print(missing_tic)\n",
    "#             for m_tic in missing_tic:\n",
    "#                 temp_dict = {'ts_code':m_tic,'trade_date':date,'open':0, 'high':0,'low':0, 'close':0, 'pre_close':0, 'change':0, 'pct_chg':0, 'volume':0, 'amount':0}\n",
    "#                 new_data = pd.DataFrame.from_dict(temp_dict,orient='index').T\n",
    "#                 temp_df = temp_df.append(new_data)\n",
    "#             processe_df.append(temp_df)\n",
    "#         else :\n",
    "#             processe_df.append(temp_df)\n",
    "#         processed_df = pd.concat(processe_df,ignore_index = True)       \n",
    "#     processed_df = processed_df.sort_values('trade_date',ascending=True).reset_index()\n",
    "#     processed_df = processed_df.drop('index',axis=1)\n",
    "#     return processed_df,date_unique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 筛选exchange_calender中每个交易节点缺失(激进)\n",
    "# def processed_date(df,selected_tics,k):\n",
    "#     date_unique = list(df['trade_date'].unique())\n",
    "#     date_sum = len(date_unique)\n",
    "#     count = 0\n",
    "#     processe_df =[]\n",
    "#     processed_df = pd.DataFrame()\n",
    "#     for date in date_unique:\n",
    "#         temp_df = df[df['trade_date'] == date]\n",
    "#         if len(temp_df) == k:\n",
    "#             processe_df.append(temp_df)\n",
    "#         else :\n",
    "#             date_unique.remove(date)\n",
    "#         processed_df = pd.concat(processe_df,ignore_index = True)       \n",
    "#     processed_df = processed_df.sort_values('trade_date',ascending=True).reset_index()\n",
    "#     processed_df = processed_df.drop('index',axis=1)\n",
    "#     return processed_df,date_unique\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# processed_df,date_unique = processed_date(df_ts,selected_tics,k)\n",
    "# print(processed_df) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# processed_df1 = processed_df.drop('volume',axis=1)\n",
    "# processed_df1 = processed_df1.sort_values(['ts_code','trade_date'],ascending=True,ignore_index=True)\n",
    "# processed_df1['trade_date'] = pd.to_datetime(processed_df1['trade_date'])\n",
    "# processed_df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "fe = FeatureEngineer(\n",
    "                    use_technical_indicator=True,\n",
    "                    tech_indicator_list = INDICATORS,\n",
    "                    use_vix=False,\n",
    "                    use_turbulence=False,\n",
    "                    user_defined_feature = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully added technical indicators\n"
     ]
    }
   ],
   "source": [
    "processed_df3 = processed_df1.rename(columns={'ts_code':'tic','trade_date':'date','vol':'volume'})\n",
    "processed_df3 = fe.preprocess_data(processed_df3)\n",
    "processed_df3 = processed_df3.fillna(method=\"ffill\").fillna(method=\"bfill\")\n",
    "processed_df3 = processed_df3.sort_values(['tic','date'],ascending=True).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ts_code</th>\n",
       "      <th>trade_date</th>\n",
       "      <th>open</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>close</th>\n",
       "      <th>pre_close</th>\n",
       "      <th>change</th>\n",
       "      <th>pct_chg</th>\n",
       "      <th>vol</th>\n",
       "      <th>amount</th>\n",
       "      <th>filled</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>600000.SH</td>\n",
       "      <td>2017-01-03</td>\n",
       "      <td>16.21</td>\n",
       "      <td>16.44</td>\n",
       "      <td>16.17</td>\n",
       "      <td>16.30</td>\n",
       "      <td>16.21</td>\n",
       "      <td>0.09</td>\n",
       "      <td>0.5600</td>\n",
       "      <td>162371.25</td>\n",
       "      <td>265043.268</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>600000.SH</td>\n",
       "      <td>2017-01-04</td>\n",
       "      <td>16.29</td>\n",
       "      <td>16.35</td>\n",
       "      <td>16.18</td>\n",
       "      <td>16.33</td>\n",
       "      <td>16.30</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.1800</td>\n",
       "      <td>296587.34</td>\n",
       "      <td>482612.222</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>600000.SH</td>\n",
       "      <td>2017-01-05</td>\n",
       "      <td>16.30</td>\n",
       "      <td>16.38</td>\n",
       "      <td>16.24</td>\n",
       "      <td>16.30</td>\n",
       "      <td>16.33</td>\n",
       "      <td>-0.03</td>\n",
       "      <td>-0.1800</td>\n",
       "      <td>264376.46</td>\n",
       "      <td>431449.126</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>600000.SH</td>\n",
       "      <td>2017-01-06</td>\n",
       "      <td>16.30</td>\n",
       "      <td>16.30</td>\n",
       "      <td>16.13</td>\n",
       "      <td>16.18</td>\n",
       "      <td>16.30</td>\n",
       "      <td>-0.12</td>\n",
       "      <td>-0.7400</td>\n",
       "      <td>171955.98</td>\n",
       "      <td>278864.536</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>600000.SH</td>\n",
       "      <td>2017-01-09</td>\n",
       "      <td>16.24</td>\n",
       "      <td>16.29</td>\n",
       "      <td>16.13</td>\n",
       "      <td>16.20</td>\n",
       "      <td>16.18</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.1200</td>\n",
       "      <td>149087.45</td>\n",
       "      <td>241579.598</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72945</th>\n",
       "      <td>601998.SH</td>\n",
       "      <td>2022-12-26</td>\n",
       "      <td>4.90</td>\n",
       "      <td>4.91</td>\n",
       "      <td>4.83</td>\n",
       "      <td>4.83</td>\n",
       "      <td>4.88</td>\n",
       "      <td>-0.05</td>\n",
       "      <td>-1.0246</td>\n",
       "      <td>189583.31</td>\n",
       "      <td>92209.197</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72946</th>\n",
       "      <td>601998.SH</td>\n",
       "      <td>2022-12-27</td>\n",
       "      <td>4.89</td>\n",
       "      <td>4.93</td>\n",
       "      <td>4.86</td>\n",
       "      <td>4.90</td>\n",
       "      <td>4.83</td>\n",
       "      <td>0.07</td>\n",
       "      <td>1.4493</td>\n",
       "      <td>170230.99</td>\n",
       "      <td>83528.189</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72947</th>\n",
       "      <td>601998.SH</td>\n",
       "      <td>2022-12-28</td>\n",
       "      <td>4.91</td>\n",
       "      <td>5.02</td>\n",
       "      <td>4.87</td>\n",
       "      <td>4.98</td>\n",
       "      <td>4.90</td>\n",
       "      <td>0.08</td>\n",
       "      <td>1.6327</td>\n",
       "      <td>209360.59</td>\n",
       "      <td>103967.749</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72948</th>\n",
       "      <td>601998.SH</td>\n",
       "      <td>2022-12-29</td>\n",
       "      <td>4.95</td>\n",
       "      <td>4.96</td>\n",
       "      <td>4.84</td>\n",
       "      <td>4.93</td>\n",
       "      <td>4.98</td>\n",
       "      <td>-0.05</td>\n",
       "      <td>-1.0040</td>\n",
       "      <td>260632.34</td>\n",
       "      <td>127533.792</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72949</th>\n",
       "      <td>601998.SH</td>\n",
       "      <td>2022-12-30</td>\n",
       "      <td>4.94</td>\n",
       "      <td>5.02</td>\n",
       "      <td>4.93</td>\n",
       "      <td>4.98</td>\n",
       "      <td>4.93</td>\n",
       "      <td>0.05</td>\n",
       "      <td>1.0142</td>\n",
       "      <td>216134.46</td>\n",
       "      <td>107621.813</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>72950 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         ts_code trade_date   open   high    low  close  pre_close  change  \\\n",
       "0      600000.SH 2017-01-03  16.21  16.44  16.17  16.30      16.21    0.09   \n",
       "1      600000.SH 2017-01-04  16.29  16.35  16.18  16.33      16.30    0.03   \n",
       "2      600000.SH 2017-01-05  16.30  16.38  16.24  16.30      16.33   -0.03   \n",
       "3      600000.SH 2017-01-06  16.30  16.30  16.13  16.18      16.30   -0.12   \n",
       "4      600000.SH 2017-01-09  16.24  16.29  16.13  16.20      16.18    0.02   \n",
       "...          ...        ...    ...    ...    ...    ...        ...     ...   \n",
       "72945  601998.SH 2022-12-26   4.90   4.91   4.83   4.83       4.88   -0.05   \n",
       "72946  601998.SH 2022-12-27   4.89   4.93   4.86   4.90       4.83    0.07   \n",
       "72947  601998.SH 2022-12-28   4.91   5.02   4.87   4.98       4.90    0.08   \n",
       "72948  601998.SH 2022-12-29   4.95   4.96   4.84   4.93       4.98   -0.05   \n",
       "72949  601998.SH 2022-12-30   4.94   5.02   4.93   4.98       4.93    0.05   \n",
       "\n",
       "       pct_chg        vol      amount  filled  \n",
       "0       0.5600  162371.25  265043.268       0  \n",
       "1       0.1800  296587.34  482612.222       0  \n",
       "2      -0.1800  264376.46  431449.126       0  \n",
       "3      -0.7400  171955.98  278864.536       0  \n",
       "4       0.1200  149087.45  241579.598       0  \n",
       "...        ...        ...         ...     ...  \n",
       "72945  -1.0246  189583.31   92209.197       0  \n",
       "72946   1.4493  170230.99   83528.189       0  \n",
       "72947   1.6327  209360.59  103967.749       0  \n",
       "72948  -1.0040  260632.34  127533.792       0  \n",
       "72949   1.0142  216134.46  107621.813       0  \n",
       "\n",
       "[72950 rows x 12 columns]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "processed_df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_df3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def delaydate(dela,full_list):\n",
    "    grouped = processed_df3.groupby('tic')\n",
    "    filtered_df = pd.DataFrame()\n",
    "    for name, group in grouped:\n",
    "        # 按'trade_date'升序排序  True=升序\n",
    "        group = group.sort_values('date', ascending=True)\n",
    "\n",
    "        # 丢弃前48个日期的数据\n",
    "        group = group.iloc[dela:]\n",
    "        filtered_df = filtered_df.append(group)\n",
    "    \n",
    "    filtered_df = filtered_df.reset_index(drop=True)\n",
    "    filtered_df = filtered_df.sort_values(['tic','date'],ascending=True,ignore_index=True)\n",
    "    return filtered_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "pro_df = processed_df1.loc[:,['open','high','low','close','vol']].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>open</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>close</th>\n",
       "      <th>vol</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>16.21</td>\n",
       "      <td>16.44</td>\n",
       "      <td>16.17</td>\n",
       "      <td>16.30</td>\n",
       "      <td>162371.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>16.29</td>\n",
       "      <td>16.35</td>\n",
       "      <td>16.18</td>\n",
       "      <td>16.33</td>\n",
       "      <td>296587.34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>16.30</td>\n",
       "      <td>16.38</td>\n",
       "      <td>16.24</td>\n",
       "      <td>16.30</td>\n",
       "      <td>264376.46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>16.30</td>\n",
       "      <td>16.30</td>\n",
       "      <td>16.13</td>\n",
       "      <td>16.18</td>\n",
       "      <td>171955.98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>16.24</td>\n",
       "      <td>16.29</td>\n",
       "      <td>16.13</td>\n",
       "      <td>16.20</td>\n",
       "      <td>149087.45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72945</th>\n",
       "      <td>4.90</td>\n",
       "      <td>4.91</td>\n",
       "      <td>4.83</td>\n",
       "      <td>4.83</td>\n",
       "      <td>189583.31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72946</th>\n",
       "      <td>4.89</td>\n",
       "      <td>4.93</td>\n",
       "      <td>4.86</td>\n",
       "      <td>4.90</td>\n",
       "      <td>170230.99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72947</th>\n",
       "      <td>4.91</td>\n",
       "      <td>5.02</td>\n",
       "      <td>4.87</td>\n",
       "      <td>4.98</td>\n",
       "      <td>209360.59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72948</th>\n",
       "      <td>4.95</td>\n",
       "      <td>4.96</td>\n",
       "      <td>4.84</td>\n",
       "      <td>4.93</td>\n",
       "      <td>260632.34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72949</th>\n",
       "      <td>4.94</td>\n",
       "      <td>5.02</td>\n",
       "      <td>4.93</td>\n",
       "      <td>4.98</td>\n",
       "      <td>216134.46</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>72950 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        open   high    low  close        vol\n",
       "0      16.21  16.44  16.17  16.30  162371.25\n",
       "1      16.29  16.35  16.18  16.33  296587.34\n",
       "2      16.30  16.38  16.24  16.30  264376.46\n",
       "3      16.30  16.30  16.13  16.18  171955.98\n",
       "4      16.24  16.29  16.13  16.20  149087.45\n",
       "...      ...    ...    ...    ...        ...\n",
       "72945   4.90   4.91   4.83   4.83  189583.31\n",
       "72946   4.89   4.93   4.86   4.90  170230.99\n",
       "72947   4.91   5.02   4.87   4.98  209360.59\n",
       "72948   4.95   4.96   4.84   4.93  260632.34\n",
       "72949   4.94   5.02   4.93   4.98  216134.46\n",
       "\n",
       "[72950 rows x 5 columns]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pro_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#出现缺失值的个数、占比\n",
    "count = len(pro_df[pro_df['open'] == 0])\n",
    "nan_rate = count/len(pro_df)\n",
    "print(count,'缺失值百分之:',nan_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "#计算技术指标到dataset中\n",
    "#Can be easily expanded\n",
    "#Currently contains a small set of tech indicators\n",
    "import talib as ta\n",
    "\n",
    "def calc_tech_ind(data):\n",
    "    #overlap \n",
    "    data['upbd'], data['midbd'], data['lowbd'] = ta.BBANDS(data[\"close\"])\n",
    "    data['dema'] = ta.DEMA(data[\"close\"], timeperiod=30)\n",
    "    data['tema'] = ta.TEMA(data[\"close\"], timeperiod=30)\n",
    "#     data['ema'] = ta.EMA(data[\"close\"], timeperiod=30)\n",
    "#     data['wma'] = ta.WMA(data[\"close\"], timeperiod=30)\n",
    "#     data['sma'] = ta.SMA(data[\"close\"], timeperiod=30)\n",
    "#     data['sarext'] = ta.SAREXT(data[\"high\"], data[\"low\"])\n",
    "    \n",
    "    #momentum\n",
    "    data['adxr'] = ta.ADXR(data[\"high\"], data[\"low\"], data[\"close\"], timeperiod=14)\n",
    "    data['apo'] = ta.APO(data[\"close\"], fastperiod=12, slowperiod=26, matype=0)\n",
    "    data['aroondown'], data['aroonup'] = ta.AROON(data[\"high\"], data[\"low\"], timeperiod=14)\n",
    "    data['cci'] = ta.CCI(data[\"high\"], data[\"low\"], data[\"close\"], timeperiod=14)\n",
    "    data['cmo'] = ta.CMO(data[\"close\"], timeperiod=14)\n",
    "    data['macd'], data['macdsignal'], data['macdhist'] = ta.MACD(data[\"close\"], fastperiod=12, slowperiod=26, signalperiod=9)\n",
    "    data['MFI'] = ta.MFI(data[\"high\"], data[\"low\"], data[\"close\"], data['vol'], timeperiod=14)\n",
    "#     data['mom'] = ta.MOM(data[\"close\"], timeperiod=10)\n",
    "#     data['plus_di'] = ta.PLUS_DI(data[\"high\"], data[\"low\"], data[\"close\"], timeperiod=14)\n",
    "#     data['ppo'] = ta.PPO(data[\"close\"], fastperiod=12, slowperiod=26, matype=0)\n",
    "#     data['roc'] = ta.ROC(data[\"close\"], timeperiod=10)\n",
    "#     data['rocp'] = ta.ROCP(data[\"close\"], timeperiod=10)\n",
    "#     data['rsi'] = ta.RSI(data[\"close\"], timeperiod=14)\n",
    "#     data['slowk'], data['slowd'] = ta.STOCH(data[\"high\"], data[\"low\"], data[\"close\"])\n",
    "#     data['fastk'], data['fastd'] = ta.STOCHF(data[\"high\"], data[\"low\"], data[\"close\"])\n",
    "#     data['trix'] = ta.TRIX(data[\"close\"], timeperiod=30)\n",
    "#     data['ultosc'] = ta.ULTOSC(data[\"high\"], data[\"low\"], data[\"close\"], timeperiod1=7, timeperiod2=14, timeperiod3=28)\n",
    "#     data['willr'] = ta.WILLR(data[\"high\"], data[\"low\"], data[\"close\"], timeperiod=14)\n",
    "    \n",
    "    #volume\n",
    "    data['ad'] = ta.AD(data[\"high\"], data[\"low\"], data[\"close\"], data['vol'])\n",
    "    data['obv'] = ta.OBV(data[\"close\"], data['vol'])\n",
    "    \n",
    "    #volitility\n",
    "    data['atr'] = ta.ATR(data[\"high\"], data[\"low\"], data[\"close\"], timeperiod=14)\n",
    "    data['natr'] = ta.NATR(data[\"high\"], data[\"low\"], data[\"close\"], timeperiod=14)\n",
    "    \n",
    "    #cycle\n",
    "    data['HT_DCPERIOD'] = ta.HT_DCPERIOD(data[\"close\"])\n",
    "#     data['HT_DCPHASE'] = ta.HT_DCPHASE(data[\"close\"])\n",
    "#     data['inphase'], data['quadrature'] = ta.HT_PHASOR(data[\"close\"])\n",
    "    \n",
    "    \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_list1 = calc_tech_ind(pro_df)\n",
    "full_list1 = full_list1.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>open</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>close</th>\n",
       "      <th>vol</th>\n",
       "      <th>upbd</th>\n",
       "      <th>midbd</th>\n",
       "      <th>lowbd</th>\n",
       "      <th>dema</th>\n",
       "      <th>tema</th>\n",
       "      <th>...</th>\n",
       "      <th>cmo</th>\n",
       "      <th>macd</th>\n",
       "      <th>macdsignal</th>\n",
       "      <th>macdhist</th>\n",
       "      <th>MFI</th>\n",
       "      <th>ad</th>\n",
       "      <th>obv</th>\n",
       "      <th>atr</th>\n",
       "      <th>natr</th>\n",
       "      <th>HT_DCPERIOD</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>16.21</td>\n",
       "      <td>16.44</td>\n",
       "      <td>16.17</td>\n",
       "      <td>16.30</td>\n",
       "      <td>162371.25</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-6.013750e+03</td>\n",
       "      <td>1.623712e+05</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>16.29</td>\n",
       "      <td>16.35</td>\n",
       "      <td>16.18</td>\n",
       "      <td>16.33</td>\n",
       "      <td>296587.34</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.207883e+05</td>\n",
       "      <td>4.589586e+05</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>16.30</td>\n",
       "      <td>16.38</td>\n",
       "      <td>16.24</td>\n",
       "      <td>16.30</td>\n",
       "      <td>264376.46</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.830203e+05</td>\n",
       "      <td>1.945821e+05</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>16.30</td>\n",
       "      <td>16.30</td>\n",
       "      <td>16.13</td>\n",
       "      <td>16.18</td>\n",
       "      <td>171955.98</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.122149e+05</td>\n",
       "      <td>2.262615e+04</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>16.24</td>\n",
       "      <td>16.29</td>\n",
       "      <td>16.13</td>\n",
       "      <td>16.20</td>\n",
       "      <td>149087.45</td>\n",
       "      <td>16.382266</td>\n",
       "      <td>16.262</td>\n",
       "      <td>16.141734</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>9.357893e+04</td>\n",
       "      <td>1.717136e+05</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72945</th>\n",
       "      <td>4.90</td>\n",
       "      <td>4.91</td>\n",
       "      <td>4.83</td>\n",
       "      <td>4.83</td>\n",
       "      <td>189583.31</td>\n",
       "      <td>4.968404</td>\n",
       "      <td>4.894</td>\n",
       "      <td>4.819596</td>\n",
       "      <td>5.023952</td>\n",
       "      <td>5.025741</td>\n",
       "      <td>...</td>\n",
       "      <td>-10.043686</td>\n",
       "      <td>0.031323</td>\n",
       "      <td>0.072882</td>\n",
       "      <td>-0.041559</td>\n",
       "      <td>46.563159</td>\n",
       "      <td>4.266368e+08</td>\n",
       "      <td>2.846765e+09</td>\n",
       "      <td>0.125167</td>\n",
       "      <td>2.591444</td>\n",
       "      <td>23.824205</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72946</th>\n",
       "      <td>4.89</td>\n",
       "      <td>4.93</td>\n",
       "      <td>4.86</td>\n",
       "      <td>4.90</td>\n",
       "      <td>170230.99</td>\n",
       "      <td>4.968404</td>\n",
       "      <td>4.894</td>\n",
       "      <td>4.819596</td>\n",
       "      <td>5.016044</td>\n",
       "      <td>5.010231</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.299823</td>\n",
       "      <td>0.025253</td>\n",
       "      <td>0.063356</td>\n",
       "      <td>-0.038104</td>\n",
       "      <td>54.979204</td>\n",
       "      <td>4.266612e+08</td>\n",
       "      <td>2.846935e+09</td>\n",
       "      <td>0.123369</td>\n",
       "      <td>2.517738</td>\n",
       "      <td>24.662880</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72947</th>\n",
       "      <td>4.91</td>\n",
       "      <td>5.02</td>\n",
       "      <td>4.87</td>\n",
       "      <td>4.98</td>\n",
       "      <td>209360.59</td>\n",
       "      <td>5.004080</td>\n",
       "      <td>4.904</td>\n",
       "      <td>4.803920</td>\n",
       "      <td>5.018630</td>\n",
       "      <td>5.010700</td>\n",
       "      <td>...</td>\n",
       "      <td>7.724246</td>\n",
       "      <td>0.026590</td>\n",
       "      <td>0.056003</td>\n",
       "      <td>-0.029413</td>\n",
       "      <td>52.641256</td>\n",
       "      <td>4.267589e+08</td>\n",
       "      <td>2.847144e+09</td>\n",
       "      <td>0.125271</td>\n",
       "      <td>2.515489</td>\n",
       "      <td>25.498844</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72948</th>\n",
       "      <td>4.95</td>\n",
       "      <td>4.96</td>\n",
       "      <td>4.84</td>\n",
       "      <td>4.93</td>\n",
       "      <td>260632.34</td>\n",
       "      <td>5.004080</td>\n",
       "      <td>4.904</td>\n",
       "      <td>4.803920</td>\n",
       "      <td>5.014490</td>\n",
       "      <td>5.001620</td>\n",
       "      <td>...</td>\n",
       "      <td>1.630525</td>\n",
       "      <td>0.023347</td>\n",
       "      <td>0.049472</td>\n",
       "      <td>-0.026125</td>\n",
       "      <td>40.117838</td>\n",
       "      <td>4.268892e+08</td>\n",
       "      <td>2.846884e+09</td>\n",
       "      <td>0.126323</td>\n",
       "      <td>2.562341</td>\n",
       "      <td>26.284145</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72949</th>\n",
       "      <td>4.94</td>\n",
       "      <td>5.02</td>\n",
       "      <td>4.93</td>\n",
       "      <td>4.98</td>\n",
       "      <td>216134.46</td>\n",
       "      <td>5.036143</td>\n",
       "      <td>4.924</td>\n",
       "      <td>4.811857</td>\n",
       "      <td>5.016757</td>\n",
       "      <td>5.002346</td>\n",
       "      <td>...</td>\n",
       "      <td>7.279009</td>\n",
       "      <td>0.024528</td>\n",
       "      <td>0.044483</td>\n",
       "      <td>-0.019955</td>\n",
       "      <td>48.561263</td>\n",
       "      <td>4.269132e+08</td>\n",
       "      <td>2.847100e+09</td>\n",
       "      <td>0.123729</td>\n",
       "      <td>2.484515</td>\n",
       "      <td>26.407984</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>72950 rows × 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        open   high    low  close        vol       upbd   midbd      lowbd  \\\n",
       "0      16.21  16.44  16.17  16.30  162371.25   0.000000   0.000   0.000000   \n",
       "1      16.29  16.35  16.18  16.33  296587.34   0.000000   0.000   0.000000   \n",
       "2      16.30  16.38  16.24  16.30  264376.46   0.000000   0.000   0.000000   \n",
       "3      16.30  16.30  16.13  16.18  171955.98   0.000000   0.000   0.000000   \n",
       "4      16.24  16.29  16.13  16.20  149087.45  16.382266  16.262  16.141734   \n",
       "...      ...    ...    ...    ...        ...        ...     ...        ...   \n",
       "72945   4.90   4.91   4.83   4.83  189583.31   4.968404   4.894   4.819596   \n",
       "72946   4.89   4.93   4.86   4.90  170230.99   4.968404   4.894   4.819596   \n",
       "72947   4.91   5.02   4.87   4.98  209360.59   5.004080   4.904   4.803920   \n",
       "72948   4.95   4.96   4.84   4.93  260632.34   5.004080   4.904   4.803920   \n",
       "72949   4.94   5.02   4.93   4.98  216134.46   5.036143   4.924   4.811857   \n",
       "\n",
       "           dema      tema  ...        cmo      macd  macdsignal  macdhist  \\\n",
       "0      0.000000  0.000000  ...   0.000000  0.000000    0.000000  0.000000   \n",
       "1      0.000000  0.000000  ...   0.000000  0.000000    0.000000  0.000000   \n",
       "2      0.000000  0.000000  ...   0.000000  0.000000    0.000000  0.000000   \n",
       "3      0.000000  0.000000  ...   0.000000  0.000000    0.000000  0.000000   \n",
       "4      0.000000  0.000000  ...   0.000000  0.000000    0.000000  0.000000   \n",
       "...         ...       ...  ...        ...       ...         ...       ...   \n",
       "72945  5.023952  5.025741  ... -10.043686  0.031323    0.072882 -0.041559   \n",
       "72946  5.016044  5.010231  ...  -1.299823  0.025253    0.063356 -0.038104   \n",
       "72947  5.018630  5.010700  ...   7.724246  0.026590    0.056003 -0.029413   \n",
       "72948  5.014490  5.001620  ...   1.630525  0.023347    0.049472 -0.026125   \n",
       "72949  5.016757  5.002346  ...   7.279009  0.024528    0.044483 -0.019955   \n",
       "\n",
       "             MFI            ad           obv       atr      natr  HT_DCPERIOD  \n",
       "0       0.000000 -6.013750e+03  1.623712e+05  0.000000  0.000000     0.000000  \n",
       "1       0.000000  2.207883e+05  4.589586e+05  0.000000  0.000000     0.000000  \n",
       "2       0.000000  1.830203e+05  1.945821e+05  0.000000  0.000000     0.000000  \n",
       "3       0.000000  1.122149e+05  2.262615e+04  0.000000  0.000000     0.000000  \n",
       "4       0.000000  9.357893e+04  1.717136e+05  0.000000  0.000000     0.000000  \n",
       "...          ...           ...           ...       ...       ...          ...  \n",
       "72945  46.563159  4.266368e+08  2.846765e+09  0.125167  2.591444    23.824205  \n",
       "72946  54.979204  4.266612e+08  2.846935e+09  0.123369  2.517738    24.662880  \n",
       "72947  52.641256  4.267589e+08  2.847144e+09  0.125271  2.515489    25.498844  \n",
       "72948  40.117838  4.268892e+08  2.846884e+09  0.126323  2.562341    26.284145  \n",
       "72949  48.561263  4.269132e+08  2.847100e+09  0.123729  2.484515    26.407984  \n",
       "\n",
       "[72950 rows x 25 columns]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_list1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_list2 = calc_tech_ind(backtest_df_reduction)\n",
    "full_list2 = full_list2.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "array_full_list = np.array(full_list1)\n",
    "array_full_list = array_full_list.reshape(k,int(len(full_list1)/k),full_list1.shape[1])\n",
    "selected_tics = sorted(selected_tics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "array_full_list1 = array_full_list[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.64600000e+01, 1.65400000e+01, 1.63700000e+01, 1.64000000e+01,\n",
       "        1.25552920e+05, 1.66250851e+01, 1.63020000e+01, 1.59789149e+01,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        4.74338735e+05, 5.14686970e+05, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00],\n",
       "       [1.64200000e+01, 1.65500000e+01, 1.63600000e+01, 1.64800000e+01,\n",
       "        1.14786630e+05, 1.66777948e+01, 1.63660000e+01, 1.60542052e+01,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        5.04545743e+05, 6.29473600e+05, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00],\n",
       "       [1.64300000e+01, 1.66400000e+01, 1.64300000e+01, 1.65400000e+01,\n",
       "        1.21806870e+05, 1.66616601e+01, 1.64500000e+01, 1.62383399e+01,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        5.10346071e+05, 7.51280470e+05, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00],\n",
       "       [1.65800000e+01, 1.66600000e+01, 1.65000000e+01, 1.66000000e+01,\n",
       "        1.42882680e+05, 1.66554848e+01, 1.65160000e+01, 1.63765152e+01,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 1.47716119e+02, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        5.46066741e+05, 8.94163150e+05, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00],\n",
       "       [1.66600000e+01, 1.66900000e+01, 1.65100000e+01, 1.65700000e+01,\n",
       "        1.46165400e+05, 1.66602111e+01, 1.65180000e+01, 1.63757889e+01,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        6.42857143e+01, 1.00000000e+02, 1.17679203e+02, 2.43243243e+01,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 7.14172970e+01,\n",
       "        4.97344941e+05, 7.47997750e+05, 1.81428571e-01, 1.09492198e+00,\n",
       "        0.00000000e+00],\n",
       "       [1.65800000e+01, 1.67000000e+01, 1.65800000e+01, 1.66900000e+01,\n",
       "        1.49852410e+05, 1.67149100e+01, 1.65760000e+01, 1.64370900e+01,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        5.71428571e+01, 1.00000000e+02, 1.20715350e+02, 3.22160149e+01,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 8.21654882e+01,\n",
       "        6.22221949e+05, 8.97850160e+05, 1.77755102e-01, 1.06503956e+00,\n",
       "        0.00000000e+00],\n",
       "       [1.66900000e+01, 1.67400000e+01, 1.66100000e+01, 1.66900000e+01,\n",
       "        1.12848690e+05, 1.67415476e+01, 1.66180000e+01, 1.64944524e+01,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        5.00000000e+01, 1.00000000e+02, 1.09594577e+02, 3.22160149e+01,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 8.09723731e+01,\n",
       "        6.48263954e+05, 8.97850160e+05, 1.74344023e-01, 1.04460170e+00,\n",
       "        0.00000000e+00],\n",
       "       [1.66900000e+01, 1.68400000e+01, 1.66100000e+01, 1.67400000e+01,\n",
       "        8.60290700e+04, 1.67841111e+01, 1.66580000e+01, 1.65318889e+01,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        4.28571429e+01, 1.00000000e+02, 1.13496377e+02, 3.54679889e+01,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 8.82094918e+01,\n",
       "        6.59485137e+05, 9.83879230e+05, 1.78319450e-01, 1.06522969e+00,\n",
       "        0.00000000e+00],\n",
       "       [1.68200000e+01, 1.68500000e+01, 1.66200000e+01, 1.66300000e+01,\n",
       "        8.17428900e+04, 1.67810299e+01, 1.66640000e+01, 1.65469701e+01,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        3.57142857e+01, 1.00000000e+02, 8.97753324e+01, 2.16415803e+01,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 8.38179590e+01,\n",
       "        5.84850325e+05, 9.02136340e+05, 1.82010918e-01, 1.09447335e+00,\n",
       "        0.00000000e+00],\n",
       "       [1.67500000e+01, 1.67800000e+01, 1.66600000e+01, 1.66600000e+01,\n",
       "        1.34558500e+05, 1.67551027e+01, 1.66820000e+01, 1.66088973e+01,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        2.85714286e+01, 9.28571429e+01, 7.95761079e+01, 2.39221543e+01,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 8.71454438e+01,\n",
       "        4.50291825e+05, 1.03669484e+06, 1.79724424e-01, 1.07877805e+00,\n",
       "        0.00000000e+00]])"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "array_full_list1[10:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(array_full_list[1][3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(array_full_list[:,:,3][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "array_full_list2 = np.array(full_list2)\n",
    "array_full_list2 = array_full_list2.reshape(k,int(len(full_list2)/k),full_list2.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.isnan(array_full_list).any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#text\n",
    "# tdata = array_full_list[0][:-1]\n",
    "ttdata = [1,2,3,4,5,6,7,8,9,10,11,12,13,14,15]\n",
    "windows = 5\n",
    "gap = 1\n",
    "batch_size = 3\n",
    "start = len(ttdata) - windows\n",
    "test_list = []\n",
    "while start >= 0:\n",
    "#     print(ttdata[start:start + windows - 1],ttdata[start + windows-1])\n",
    "    segdata = ttdata[start:start + windows]\n",
    "#     segclose = ttdata[start:start + windows]\n",
    "    test_list.extend([segdata] * batch_size)\n",
    "#     test_list.append(segdata)\n",
    "    start = start - gap\n",
    "    print(test_list,'hhhhhhhhhhhhhhh',segdata)\n",
    "    \n",
    "# print(np.array(test_list)[::-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #generate x, y, z, zp quadruples\n",
    "# #segment x, y, z trios to sequence according to $timeStep and $gap\n",
    "# #x: historical data w/ technical analysis indicator\n",
    "# #y: closing price of t+1\n",
    "# #z:  difference between t+1 and t step's closing price\n",
    "\n",
    "# def toSequential(idx, full_list, timeStep=48, gap=4):\n",
    "#     #closing: from id=0 to last\n",
    "#     closing=full_list[idx][:, 3]\n",
    "#     #data from id=0 to second to last\n",
    "#     data=full_list[idx][:-1]\n",
    "#     #calculating number of available sequential samples\n",
    "#     data_length=len(data)\n",
    "#     count=(data_length-timeStep)//gap+1\n",
    "#     stockSeq=[]\n",
    "#     labelSeq=[]\n",
    "#     diffSeq=[]\n",
    "#     realDiffSeq=[]\n",
    "    \n",
    "#     start = data_length - timeStep\n",
    "#     while start >= 0:\n",
    "#         segData = data[start:start + timeStep - 1]\n",
    "#         segClosing = closing[start:start + timeStep]\n",
    "#         std_dev = segData.std(axis=0, keepdims=True)\n",
    "#         std_dev_nonzero = np.where(std_dev == 0, 1, std_dev)  # 处理分母为零的情况\n",
    "#         segDataNorm = np.nan_to_num((segData - segData.mean(axis=0, keepdims=True)) / std_dev_nonzero)\n",
    "#         std_dev_close = segClosing.std()\n",
    "#         std_dev_close_nonzero = np.where(std_dev_close == 0, 1, std_dev_close)\n",
    "#         segClosingNorm=(segClosing-segClosing.mean())/std_dev_close_nonzero\n",
    "#         stockSeq.append(segDataNorm)\n",
    "#         labelSeq.append(segClosingNorm[1:])\n",
    "# #         print(np.isnan(labelSeq).any())\n",
    "#         diffSeq.append(segClosingNorm[1:]-segClosingNorm[:-1])\n",
    "#         realDiffSeq.append(segClosing[1:]-segClosing[:-1])       \n",
    "#         start = start - gap\n",
    "#     stockSeq=np.array(stockSeq)[::-1]\n",
    "#     labelSeq=np.array(labelSeq)[::-1]\n",
    "#     diffSeq=np.array(diffSeq)[::-1]\n",
    "#     realDiffSeq=np.array(realDiffSeq)[::-1]\n",
    "    \n",
    "#     return stockSeq.astype('float32') , labelSeq.astype('float32'), diffSeq.astype('float32'), realDiffSeq.astype('float32')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataloader的构建"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 输入是 50 * feature_size   full_list的形状是(full_date_range,k,feature_size)\n",
    "\n",
    "def toSequential_train(full_list, split_rate = 0.7, seq_len = 48 , gap = 3):\n",
    "    data_length = int(len(full_list)*0.7)\n",
    "    print(data_length)\n",
    "    closing = full_list[:data_length+1,3]\n",
    "    data = full_list[:data_length,:]\n",
    "    count = (data_length - seq_len) // gap + 1\n",
    "    stockSeq=[]\n",
    "    labelSeq=[]\n",
    "    diffSeq=[]\n",
    "    realDiffSeq=[]\n",
    "    \n",
    "    for i in range(count):\n",
    "        #segData dims: [timestep, feature count]\n",
    "        \n",
    "        segData = data[gap * i: gap * i + seq_len]\n",
    "        segClosing = closing[gap * i: gap * i + seq_len + 1]\n",
    "        \n",
    "        #segDiff=diff[gap*i:gap*i+timeStep]\n",
    "        #normalization\n",
    "        \n",
    "        std_dev = segData.std(axis=0, keepdims=True)\n",
    "        std_dev_nonzero = np.where(std_dev == 0, 1, std_dev)  # 处理分母为零的情况\n",
    "        \n",
    "#         segDataNorm = np.nan_to_num((segData - segData.mean(axis=0, keepdims=True)) / std_dev_nonzero)\n",
    "        segDataNorm = np.nan_to_num((segData-segData.mean(axis=0, keepdims=True))/segData.std(axis=0, keepdims=True))\n",
    "\n",
    "        std_close = segClosing.std()\n",
    "        std_segClosing = np.where(std_close == 0, 1, std_close)\n",
    "        segClosingNorm=(segClosing-segClosing.mean())/std_segClosing\n",
    "#         segDiff=(segDiff-segDiff.mean())/segDiff.std()\n",
    "        \n",
    "        stockSeq.append(segDataNorm)\n",
    "        labelSeq.append(segClosingNorm[1:])\n",
    "        diffSeq.append(segClosingNorm[1:]-segClosingNorm[:-1])\n",
    "        realDiffSeq.append(segClosing[1:]-segClosing[:-1])\n",
    "#         print(len(labelSeq))\n",
    "    stockSeq=np.array(stockSeq)\n",
    "    labelSeq=np.array(labelSeq)\n",
    "    diffSeq=np.array(diffSeq)\n",
    "    realDiffSeq=np.array(realDiffSeq)\n",
    "    return stockSeq.astype('float32') , labelSeq.astype('float32'), diffSeq.astype('float32'), realDiffSeq.astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 输入是 50 * feature_size   full_list的形状是(full_date_range,k,feature_size)\n",
    "\n",
    "def toSequential_val(full_list, split_rate = 0.7, seq_len = 48 , gap = 1):\n",
    "    data_length = int(len(full_list)*0.7)\n",
    "    print(data_length)\n",
    "    closing = full_list[data_length:,3]\n",
    "    data = full_list[data_length:-1,:]\n",
    "    count = (len(full_list) - data_length - 1 - seq_len) // gap + 1\n",
    "    stockSeq=[]\n",
    "    labelSeq=[]\n",
    "    diffSeq=[]\n",
    "    realDiffSeq=[]\n",
    "    \n",
    "    for i in range(count):\n",
    "        #segData dims: [timestep, feature count]\n",
    "        \n",
    "        segData = data[gap * i: gap * i + seq_len]\n",
    "        segClosing = closing[gap * i: gap * i + seq_len + 1]\n",
    "        \n",
    "        #segDiff=diff[gap*i:gap*i+timeStep]\n",
    "        #normalization\n",
    "        \n",
    "        std_dev = segData.std(axis=0, keepdims=True)\n",
    "        std_dev_nonzero = np.where(std_dev == 0, 1, std_dev)  # 处理分母为零的情况\n",
    "        \n",
    "#         segDataNorm = np.nan_to_num((segData - segData.mean(axis=0, keepdims=True)) / std_dev_nonzero)\n",
    "        segDataNorm = np.nan_to_num((segData-segData.mean(axis=0, keepdims=True))/segData.std(axis=0, keepdims=True))\n",
    "\n",
    "        std_close = segClosing.std()\n",
    "        std_segClosing = np.where(std_close == 0, 1, std_close)\n",
    "        segClosingNorm=(segClosing-segClosing.mean())/std_segClosing\n",
    "#         segDiff=(segDiff-segDiff.mean())/segDiff.std()\n",
    "        \n",
    "        stockSeq.append(segDataNorm)\n",
    "        labelSeq.append(segClosingNorm[1:])\n",
    "        diffSeq.append(segClosingNorm[1:]-segClosingNorm[:-1])\n",
    "        realDiffSeq.append(segClosing[1:]-segClosing[:-1])\n",
    "#         print(len(labelSeq))\n",
    "    stockSeq=np.array(stockSeq)\n",
    "    labelSeq=np.array(labelSeq)\n",
    "    diffSeq=np.array(diffSeq)\n",
    "    realDiffSeq=np.array(realDiffSeq)\n",
    "    return stockSeq.astype('float32') , labelSeq.astype('float32'), diffSeq.astype('float32'), realDiffSeq.astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[2, 3, 4, 5, 6]"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cc = [1,2,3,4,5]\n",
    "dd = [1,2,3,4,5,6]\n",
    "count = (6-2)/1+1\n",
    "dd[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "def toSequential_back(full_list, seq_len = 48, gap = 1):\n",
    "    closing = full_list[:,3]\n",
    "    data = full_list\n",
    "    data_length = len(data)\n",
    "    count = (data_length - seq_len) // gap + 1\n",
    "    stockSeq=[]\n",
    "    labelSeq=[]\n",
    "    diffSeq=[]\n",
    "    realDiffSeq=[]\n",
    "    \n",
    "    start = data_length - seq_len\n",
    "    i=0\n",
    "    while start >= 0:\n",
    "        segData = data[start:start + seq_len]\n",
    "        std_dev = segData.std(axis=0, keepdims=True)\n",
    "        std_dev_nonzero = np.where(std_dev == 0, 1, std_dev)  # 处理分母为零的情况\n",
    "        segDataNorm = np.nan_to_num((segData - segData.mean(axis=0, keepdims=True)) / std_dev_nonzero)\n",
    "        #复制batch_size个\n",
    "        stockSeq.append(segDataNorm)\n",
    "#         stockSeq.extend([segDataNorm] * batch_size)\n",
    "#         stockSeq.append(segDataNorm)   \n",
    "        start = start - gap\n",
    "        i +=1\n",
    "    stockSeq=np.array(stockSeq)[::-1]\n",
    "#     print(i)\n",
    "    return stockSeq.astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "#input each step:  vector including [stock info, tech indicators]\n",
    "#output each step: closing price t+1, price diff between t+1 and t\n",
    "#full_list: output from get_data_set\n",
    "\n",
    "class StockDataset_train(Dataset):\n",
    "    def __init__(self, split_rate, full_list, seq_len = 128, gap=3):\n",
    "\n",
    "        X, y, z, zp=toSequential_train(full_list, split_rate=0.7, seq_len = seq_len, gap = gap)\n",
    "\n",
    "        self.X = X\n",
    "        self.y = y\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.y)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "\n",
    "        data=self.X[index]\n",
    "        label1=self.y[index]\n",
    "\n",
    "        return (data, label1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "class StockDataset_val(Dataset):\n",
    "    def __init__(self, split_rate, full_list, seq_len=128, gap=2):\n",
    "\n",
    "        X, y, z, zp=toSequential_val(full_list, split_rate=0.7, seq_len = seq_len, gap = gap)\n",
    "\n",
    "        self.X = X\n",
    "        self.y = y\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.y)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "\n",
    "        data=self.X[index]\n",
    "        label1=self.y[index]\n",
    "\n",
    "        return (data, label1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "#input each step:  vector including [stock info, tech indicators]\n",
    "#output each step: closing price t+1, price diff between t+1 and t\n",
    "#full_list: output from get_data_set\n",
    "\n",
    "class StockDataset_back(Dataset):\n",
    "    def __init__(self, full_list, seq_len = 96, gap = 1):\n",
    "\n",
    "        X = toSequential_back(full_list, seq_len = seq_len, gap = gap)\n",
    "\n",
    "        self.X = X\n",
    "\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.y)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "\n",
    "        data=self.X[index]\n",
    "\n",
    "        return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1021\n",
      "1021\n"
     ]
    }
   ],
   "source": [
    "\n",
    "val_iter = DataLoader(StockDataset_val(split_rate = 0.7,full_list = array_full_list1), shuffle=True, batch_size=64, num_workers=0,drop_last=True)\n",
    "train_iter = DataLoader(StockDataset_train(split_rate = 0.7,full_list = array_full_list1), shuffle=True, batch_size=64, num_workers=0,drop_last=True)\n",
    "back_iter = DataLoader(StockDataset_back(full_list = array_full_list1), shuffle=False, batch_size=64, num_workers=0,drop_last=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25\n",
      "25\n",
      "25\n",
      "25\n",
      "25\n",
      "25\n",
      "25\n",
      "25\n",
      "25\n",
      "25\n",
      "25\n"
     ]
    }
   ],
   "source": [
    "for batch in train_iter:\n",
    "    print(len(batch[0][0][0]))\n",
    "for batch in val_iter:\n",
    "    print(len(batch[0][0][0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#generate x, y, z, zp quadruples\n",
    "#segment x, y, z trios to sequence according to $timeStep and $gap\n",
    "#x: historical data w/ technical analysis indicator\n",
    "#y: closing price of t+1\n",
    "#z:  difference between t+1 and t step's closing price\n",
    "\n",
    "def toSequential_train1(idx, full_list, timeStep=48, gap=4):\n",
    "    #closing: from id=0 to last\n",
    "    closing=full_list[idx][:, 3]\n",
    "#     closingNorm = (closing - closing.mean())/closing.std()\n",
    "    #data from id=0 to second to last\n",
    "    data=full_list[idx][:-1]\n",
    "    #calculating number of available sequential samples\n",
    "    data_length=len(data)\n",
    "    count=(data_length-timeStep)//gap+1\n",
    "    stockSeq=[]\n",
    "    labelSeq=[]\n",
    "    diffSeq=[]\n",
    "    realDiffSeq=[]\n",
    "    for i in range(count):\n",
    "        #segData dims: [timestep, feature count]       \n",
    "        segData=data[gap*i:gap*i+timeStep]\n",
    "        segClosing=closing[gap*i:gap*i+timeStep+1]\n",
    "        #segDiff=diff[gap*i:gap*i+timeStep]\n",
    "        #normalization\n",
    "        \n",
    "        std_dev = segData.std(axis=0, keepdims=True)\n",
    "        std_dev_nonzero = np.where(std_dev == 0, 1, std_dev)  # 处理分母为零的情况\n",
    "#         segDataNorm = np.nan_to_num((segData - segData.mean(axis=0, keepdims=True)) / std_dev_nonzero)\n",
    "        segDataNorm=np.nan_to_num((segData-segData.mean(axis=0, keepdims=True))/segData.std(axis=0, keepdims=True))\n",
    "    \n",
    "        std_close = segClosing.std()\n",
    "        std_segClosing = np.where(std_close == 0, 1, std_close)\n",
    "        segClosingNorm=(segClosing-segClosing.mean())/std_segClosing\n",
    "#         segDiff=(segDiff-segDiff.mean())/segDiff.std()\n",
    "        \n",
    "        stockSeq.append(segDataNorm)\n",
    "        labelSeq.append(segClosingNorm[1:])\n",
    "        diffSeq.append(segClosingNorm[1:]-segClosingNorm[:-1])\n",
    "        realDiffSeq.append(segClosing[1:]-segClosing[:-1])\n",
    "    stockSeq=np.array(stockSeq)\n",
    "    labelSeq=np.array(labelSeq)\n",
    "    diffSeq=np.array(diffSeq)\n",
    "    realDiffSeq=np.array(realDiffSeq)\n",
    "    return stockSeq.astype('float32') , labelSeq.astype('float32'), diffSeq.astype('float32'), realDiffSeq.astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#input each step:  vector including [stock info, tech indicators]\n",
    "#output each step: closing price t+1, price diff between t+1 and t\n",
    "#full_list: output from get_data_set\n",
    "\n",
    "class StockDataset(Dataset):\n",
    "    def __init__(self, id_list, full_list, transform=None, timestep=48, gap=3):\n",
    "        self.transform=transform\n",
    "        self.id_list=id_list\n",
    "        \n",
    "        stock_cohort=[]\n",
    "        closing_cohort=[]\n",
    "        diff_cohort=[]\n",
    "        real_diff_cohort=[]\n",
    "        \n",
    "        #load data into cohort\n",
    "        for i in self.id_list:\n",
    "            X, y, z, zp=toSequential_train1(i, full_list, timeStep=timestep, gap=gap)\n",
    "            stock_cohort.append(X)\n",
    "            closing_cohort.append(y)\n",
    "            diff_cohort.append(z)\n",
    "            real_diff_cohort.append(zp)\n",
    "        self.X=np.concatenate(stock_cohort, axis=0)\n",
    "        self.y=np.concatenate(closing_cohort, axis=0)\n",
    "        self.z=np.concatenate(diff_cohort, axis=0)  \n",
    "        self.zp=np.concatenate(real_diff_cohort, axis=0)\n",
    "        print(self.X)\n",
    "    def __len__(self):\n",
    "        return len(self.y)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        \"\"\"\n",
    "        data returned in the format of \n",
    "        \"\"\"\n",
    "        if torch.is_tensor(idx):\n",
    "            idx=idx.tolist()\n",
    "        \n",
    "        data=self.X[idx]\n",
    "        label1=self.y[idx]\n",
    "        label2=self.z[idx]\n",
    "        label3=self.zp[idx]\n",
    "        if self.transform:\n",
    "            data=self.transform(data)\n",
    "        return (data, label1, label2, label3)\n",
    "    \n",
    "    \n",
    "    def getDS(self):\n",
    "        return self.X, self.y, self.z, self.zp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#generate x, y, z, zp quadruples\n",
    "#segment x, y, z trios to sequence according to $timeStep and $gap\n",
    "#x: historical data w/ technical analysis indicator\n",
    "#y: closing price of t+1\n",
    "#z:  difference between t+1 and t step's closing price\n",
    "\n",
    "def toSequential_train(idx, full_list, timeStep=48, gap=4):\n",
    "    #closing: from id=0 to last\n",
    "    closing=full_list[idx][:, 3]\n",
    "    closingNorm = (closing - closing.mean())/closing.std()\n",
    "    #data from id=0 to second to last\n",
    "    data=full_list[idx][:-1]\n",
    "    #calculating number of available sequential samples\n",
    "    data_length=len(data)\n",
    "    count=(data_length-timeStep)//gap+1\n",
    "    stockSeq=[]\n",
    "    labelSeq=[]\n",
    "    diffSeq=[0,]\n",
    "    realDiffSeq=[0,]\n",
    "    for i in range(count-1):\n",
    "        #segData dims: [timestep, feature count]       \n",
    "        segData=data[gap*i:gap*i+timeStep]\n",
    "        segClosing=closingNorm[gap*i+timeStep]\n",
    "        #segDiff=diff[gap*i:gap*i+timeStep]\n",
    "        #normalization\n",
    "        \n",
    "        std_dev = segData.std(axis=0, keepdims=True)\n",
    "        std_dev_nonzero = np.where(std_dev == 0, 1, std_dev)  # 处理分母为零的情况\n",
    "        segDataNorm = np.nan_to_num((segData - segData.mean(axis=0, keepdims=True)) / std_dev_nonzero)\n",
    "#       segDataNorm=np.nan_to_num((segData-segData.mean(axis=0, keepdims=True))/segData.std(axis=0, keepdims=True))\n",
    "#       segClosingNorm=(segClosing-segClosing.mean())/segClosing.std()\n",
    "        #segDiff=(segDiff-segDiff.mean())/segDiff.std()\n",
    "        \n",
    "        stockSeq.append(segDataNorm)\n",
    "        labelSeq.append(segClosing)\n",
    "        diffSeq.append(segClosing-diffSeq[-1])\n",
    "        realDiffSeq.append(closing[gap*i+timeStep]-realDiffSeq[-1])\n",
    "    stockSeq=np.array(stockSeq)\n",
    "    labelSeq=np.array(labelSeq)\n",
    "    diffSeq=np.array(diffSeq)\n",
    "    realDiffSeq=np.array(realDiffSeq)\n",
    "    return stockSeq.astype('float32') , labelSeq.astype('float32'), diffSeq.astype('float32'), realDiffSeq.astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def toSequential_back(idx, full_list, timeStep = 48, gap = 1,batch_size = 64):\n",
    "    #closing: from id=0 to last\n",
    "    closing=full_list[idx][:, 3]\n",
    "    #data from id=0 to second to last\n",
    "    data=full_list[idx][:-1]\n",
    "    #calculating number of available sequential samples\n",
    "    data_length=len(data)\n",
    "    count=(data_length-timeStep)//gap+1\n",
    "    stockSeq=[]\n",
    "    labelSeq=[]\n",
    "    diffSeq=[]\n",
    "    realDiffSeq=[]\n",
    "    \n",
    "    start = data_length - timeStep\n",
    "    i=0\n",
    "    while start >= 0:\n",
    "        segData = data[start:start + timeStep]\n",
    "        std_dev = segData.std(axis=0, keepdims=True)\n",
    "        std_dev_nonzero = np.where(std_dev == 0, 1, std_dev)  # 处理分母为零的情况\n",
    "        segDataNorm = np.nan_to_num((segData - segData.mean(axis=0, keepdims=True)) / std_dev_nonzero)\n",
    "        #复制batch_size个\n",
    "        stockSeq.extend([segDataNorm] * batch_size)\n",
    "#         stockSeq.append(segDataNorm)   \n",
    "        start = start - gap\n",
    "        i +=1\n",
    "    stockSeq=np.array(stockSeq)[::-1]\n",
    "#     print(i)\n",
    "    return stockSeq.astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#input each step:  vector including [stock info, tech indicators]\n",
    "#output each step: closing price t+1, price diff between t+1 and t\n",
    "#full_list: output from get_data_set\n",
    "\n",
    "class StockDataset_back(Dataset):\n",
    "    def __init__(self, id_list, full_list, transform=None, timestep=48, gap=1):\n",
    "        self.transform=transform\n",
    "        self.id_list=id_list\n",
    "        \n",
    "        stock_cohort=[]\n",
    "        \n",
    "        #load data into cohort\n",
    "        for i in self.id_list:\n",
    "            X=toSequential_back(i, full_list, timeStep=timestep, gap=gap)\n",
    "            stock_cohort.append(X)\n",
    "        self.X=np.concatenate(stock_cohort, axis=0)\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        \"\"\"\n",
    "        data returned in the format of \n",
    "        \"\"\"\n",
    "        if torch.is_tensor(idx):\n",
    "            idx=idx.tolist()\n",
    "        \n",
    "        data=self.X[idx]\n",
    "        if self.transform:\n",
    "            data=self.transform(data)\n",
    "        return data\n",
    "        \n",
    "    def getDS(self):\n",
    "        return self.X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Generation of training, validation, and testing dataset\n",
    "def DataIterGen(test_id_list, val_id_list, name_list, full_list, demo=False):\n",
    "    \"\"\"\n",
    "    test_id_list: id of subjects for testing\n",
    "    val_id_list: id of subjects for validation\n",
    "    other subjects for training\n",
    "    full_list=get_data_set(name_list), preprocessed\n",
    "    demo: when demo mode is True, only test_iter is returned, with data from\n",
    "    first entry of test_id_list (single stock)\n",
    "    \"\"\"\n",
    "    name_count=len(name_list)\n",
    "\n",
    "    if demo:\n",
    "        test_iter=DataLoader(StockDataset(test_id_list[0:1], full_list, timestep=24, gap=1), shuffle=False, batch_size=64, num_workers=0)\n",
    "        print(f'Demo with stock: {name_list[test_id_list[0]]} ')\n",
    "        return test_iter\n",
    "    else:\n",
    "        all_ids = list(range(name_count))\n",
    "        train_id_list = list(set(all_ids) - set(test_id_list) - set(val_id_list))\n",
    "#         partial_list=full_list[train_list,:,:]\n",
    "        test_iter=DataLoader(StockDataset(test_id_list, full_list), batch_size=64, num_workers=0,drop_last=True)\n",
    "        val_iter=DataLoader(StockDataset_back(val_id_list, full_list), batch_size=64, num_workers=0,drop_last=True)\n",
    "        train_iter=DataLoader(StockDataset(train_id_list, full_list), shuffle=True, batch_size=64, num_workers=0,drop_last=True)\n",
    "        print(f'Val: {[name_list[val_id] for val_id in val_id_list]}, Test: {[name_list[test_id] for test_id in test_id_list]}, Train: {[name_list[train_id] for train_id in train_id_list]} ')\n",
    "        return train_iter, val_iter, test_iter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mm = [1,2,3,4,5,6,7]\n",
    "rate = 0.7\n",
    "print(mm[:int(len(mm)*rate)],mm[int(len(mm)*rate):])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_iter, val_iter, test_iter = DataIterGen([3,4,5,9,10],[7,11,13,14],selected_tics,array_full_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(array_full_list[0][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class Transformer(nn.Module):\n",
    "    def __init__(self, input_size, d_model, d_ff, num_heads,env_size, num_layers,dropout_rate):\n",
    "        super(Transformer, self).__init__()\n",
    "        self.embedding = nn.Linear(input_size, d_model)\n",
    "        self.encode = Encoder(d_model, d_ff, num_heads, num_layers,dropout_rate)\n",
    "        self.linear1 = nn.Linear(d_model, env_size)\n",
    "        self.rule = nn.ReLU()\n",
    "        self.linear2 = nn.Linear(env_size,1)\n",
    "        \n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.embedding(x)\n",
    "#         print(x.shape)\n",
    "        x = x.permute(1,0,2)\n",
    "        encoded = self.encode(x)\n",
    "        encoded = self.linear1(encoded)\n",
    "        x = self.rule(encoded)\n",
    "        x = self.linear2(x)\n",
    "#         print(x.shape)\n",
    "        decoded = x.permute(1,0,2)\n",
    "        return decoded, encoded.permute(1,0,2)[0,-1,:]  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "    def __init__(self, d_model, d_ff, num_heads, num_layers,dropout_rate):\n",
    "        super(Encoder, self).__init__()\n",
    "        self.layers = nn.ModuleList([EncoderLayer(d_model, d_ff, num_heads, dropout_rate) for _ in range(num_layers)])\n",
    "\n",
    "    def forward(self, x):\n",
    "        for layer in self.layers:\n",
    "            x = layer(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EncoderLayer(nn.Module):\n",
    "    def __init__(self, d_model, d_ff, num_heads,dropout_rate):\n",
    "        super(EncoderLayer, self).__init__()\n",
    "        self.self_attention = nn.MultiheadAttention(d_model, num_heads)\n",
    "#         self.dropout1 = nn.Dropout(dropout_rate)\n",
    "        self.feed_forward = FeedForward(d_model, d_ff, dropout_rate)\n",
    "        self.norm1 = nn.LayerNorm(d_model)\n",
    "        self.norm2 = nn.LayerNorm(d_model)\n",
    "\n",
    "    def forward(self, x):\n",
    "        residual = x  # 保存输入的残差连接\n",
    "        encoder_mask = torch.triu(torch.ones(x.size(0), x.size(0)), diagonal=1).bool().to(device)\n",
    "        # Self-Attention\n",
    "        x, _ = self.self_attention(x, x, x,attn_mask=encoder_mask)\n",
    "#         x = self.dropout1(x)\n",
    "        x = x + residual  # 残差连接\n",
    "        x = self.norm1(x)  # Add & Norm\n",
    "\n",
    "        residual = x  # 保存 Self-Attention 后的残差连接\n",
    "\n",
    "        # Feed-Forward\n",
    "        x = self.feed_forward(x)\n",
    "        x = x + residual  # 残差连接\n",
    "        x = self.norm2(x)  # Add & Norm\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FeedForward(nn.Module):\n",
    "    def __init__(self, d_model, d_ff, dropout_rate):\n",
    "        super(FeedForward, self).__init__()\n",
    "        self.linear1 = nn.Linear(d_model, d_ff)\n",
    "        self.dropout1 = nn.Dropout(dropout_rate)\n",
    "        self.linear2 = nn.Linear(d_ff, d_model)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.linear1(x))\n",
    "        x = self.dropout1(x)\n",
    "        x = self.linear2(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "#模型训练\n",
    "def train(model, train_iter, optimizer, num_epochs): \n",
    "    # 训练循环\n",
    "    train_losses = []\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        total_loss = 0.0\n",
    "        enVec_list = []\n",
    "        for X, y in train_iter:  \n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            inputs = X.to(device)\n",
    "            targets = y.unsqueeze(2).to(device)\n",
    "            pred,enVec = model(inputs)\n",
    "            enVec_list.append(enVec)\n",
    "#             print(pred,targets)\n",
    "            loss = nn.MSELoss()(pred, targets)  \n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            total_loss += loss.item()\n",
    "            \n",
    "        train_losses.append(total_loss/len(train_iter))\n",
    "        # 打印每个 epoch 的损失\n",
    "        print(f\"Epoch {epoch+1}: Loss: {total_loss/len(train_iter):.4f}\")\n",
    "        \n",
    "    %matplotlib inline    \n",
    "        # 绘制损失变化曲线\n",
    "    plt.plot(range(1, num_epochs+1), train_losses, label='Training Loss')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.title('Training Loss over Epochs')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "    \n",
    "    return enVec_list\n",
    "\n",
    "# 模型评估\n",
    "def val(model, val_iter):\n",
    "    model.eval()\n",
    "    total_loss = 0.0\n",
    "    enVec_list = []\n",
    "    with torch.no_grad():\n",
    "        for X, y in val_iter: \n",
    "            inputs = X.to(device)\n",
    "            targets = y.unsqueeze(2).to(device)\n",
    "            pred, enVec = model(inputs)\n",
    "            enVec_list.append(enVec)\n",
    "            loss = nn.MSELoss()(pred, targets)  \n",
    "            total_loss += loss.item()\n",
    "    print(f\"val Loss: {total_loss/len(val_iter):.4f}\")\n",
    "    return enVec_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "#模型训练\n",
    "def train(model, train_iter, optimizer, num_epochs): \n",
    "    # 训练循环\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        total_loss = 0.0\n",
    "        enVec_list = []\n",
    "        predictions = []  # 保存每个epoch的一些样本的预测值\n",
    "        targets_list = []  # 保存每个epoch的一些样本的真实值\n",
    "        for X, y in train_iter:  \n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            inputs = X.to(device)\n",
    "            targets = y.unsqueeze(2).to(device)\n",
    "            pred, enVec = model(inputs)\n",
    "            enVec_list.append(enVec)\n",
    "            \n",
    "            # 保存一些样本的预测值和真实值\n",
    "            if np.random.rand() < 0.1:  # 以10%的概率保存样本\n",
    "                predictions.append(pred.cpu().detach().numpy())\n",
    "                targets_list.append(targets.cpu().detach().numpy())\n",
    "            \n",
    "            loss = nn.MSELoss()(pred, targets)  \n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            total_loss += loss.item()\n",
    "\n",
    "        # 打印每个 epoch 的损失\n",
    "        print(f\"Epoch {epoch+1}: Loss: {total_loss/len(train_iter):.4f}\")\n",
    "        \n",
    "        # 绘制一些样本的预测值与真实值图\n",
    "        if epoch % 5 == 0:  # 每5个epoch绘制一次\n",
    "            plot_predictions(targets_list, predictions, epoch)\n",
    "\n",
    "    return enVec_list\n",
    "\n",
    "# 模型评估\n",
    "def val(model, val_iter):\n",
    "    model.eval()\n",
    "    total_loss = 0.0\n",
    "    enVec_list = []\n",
    "    with torch.no_grad():\n",
    "        for X, y in val_iter: \n",
    "            inputs = X.to(device)\n",
    "            targets = y.unsqueeze(2).to(device)\n",
    "            pred, enVec = model(inputs)\n",
    "            enVec_list.append(enVec)\n",
    "            loss = nn.MSELoss()(pred, targets)  \n",
    "            total_loss += loss.item()\n",
    "    print(f\"val Loss: {total_loss/len(val_iter):.4f}\")\n",
    "    return enVec_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_predictions(targets_list, predictions, epoch):\n",
    "    targets = np.concatenate(targets_list, axis=0)\n",
    "    predictions = np.concatenate(predictions, axis=0)\n",
    "    \n",
    "    plt.figure(figsize=(10, 6))\n",
    "    for i in range(min(5, targets.shape[0])):  # 绘制前5个样本\n",
    "        plt.subplot(5, 1, i+1)\n",
    "        plt.plot(targets[i], label='True')\n",
    "        plt.plot(predictions[i], label='Predicted')\n",
    "        plt.title(f'Sample {i+1} - Epoch {epoch+1}')\n",
    "        plt.legend()\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(model,back_iter):\n",
    "    enVec_list = []\n",
    "    with torch.no_grad():\n",
    "        for X in back_iter:\n",
    "            inputs = X.to(device)\n",
    "            _,enVec = model(inputs)\n",
    "            enVec_list.append(enVec)\n",
    "    return enVec_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "#define device\n",
    "def try_gpu(i=0):\n",
    "    \"\"\"Return gpu(i) if exists, otherwise return cpu().\"\"\"\n",
    "    if torch.cuda.device_count() >= i + 1:\n",
    "        return torch.device(f'cuda:{i}')\n",
    "    return torch.device('cpu')\n",
    "device=try_gpu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Loss: 0.6371\n",
      "Epoch 2: Loss: 0.3190\n",
      "Epoch 3: Loss: 0.2331\n",
      "Epoch 4: Loss: 0.1837\n",
      "Epoch 5: Loss: 0.1683\n",
      "Epoch 6: Loss: 0.1568\n",
      "Epoch 7: Loss: 0.1410\n",
      "Epoch 8: Loss: 0.1270\n",
      "Epoch 9: Loss: 0.1239\n",
      "Epoch 10: Loss: 0.1122\n",
      "Epoch 11: Loss: 0.1087\n",
      "Epoch 12: Loss: 0.1077\n",
      "Epoch 13: Loss: 0.1036\n",
      "Epoch 14: Loss: 0.0985\n",
      "Epoch 15: Loss: 0.0878\n",
      "Epoch 16: Loss: 0.0904\n",
      "Epoch 17: Loss: 0.1036\n",
      "Epoch 18: Loss: 0.0980\n",
      "Epoch 19: Loss: 0.0931\n",
      "Epoch 20: Loss: 0.0833\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val Loss: 0.0861\n"
     ]
    }
   ],
   "source": [
    "# 定义模型\n",
    "%matplotlib inline   \n",
    "model = Transformer(input_size = 25, d_model = 64 , num_layers = 2, d_ff = 64 ,num_heads = 4,env_size =20,dropout_rate=0.2)\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.01)\n",
    "outcoming =train(model,train_iter,optimizer,20)\n",
    "valtest =val(model,val_iter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# feature_enginner\n",
    "import time \n",
    "start_time = time.time()\n",
    "alltic_list = [i for i in range(k)]\n",
    "\n",
    "def Feature_enginner(model, processed_df, full_list, alltic_list, batch_size=64, k=20, env_size=40,dela = 48):\n",
    "    back_iter = DataLoader(StockDataset_back([i for i in range(k)],full_list), shuffle=False, batch_size=batch_size, num_workers=0,drop_last=False)\n",
    "    \n",
    "    new_state = predict(model,back_iter)\n",
    "    print(1)\n",
    "    concatenated_tensor = torch.cat(new_state, dim=0)\n",
    "    print(2)\n",
    "    concatenated_tensor = concatenated_tensor.view(-1,env_size)\n",
    "    print(3)\n",
    "    feature_df = pd.DataFrame(concatenated_tensor.numpy())\n",
    "    print(4)\n",
    "    \n",
    "    full_delay_df = delaydate(dela ,processed_df)\n",
    "    \n",
    "    merged_df = pd.concat([full_delay_df, feature_df], axis=1)\n",
    "    merged_df = merged_df.loc[:,['tic','date','close'] + INDICATORS + [i for i in range(env_size)]]\n",
    "    merged_df.columns = ['tic','date','close'] + INDICATORS + [f\"temporal_feature_{i}\" for i in range(env_size)]\n",
    "    end_time = time.time()\n",
    "    print('总计消耗时间:',(end_time - start_time)/60)\n",
    "    return merged_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "addfeature_df = Feature_enginner(model, processed_df1, array_full_list, alltic_list, batch_size=64, k=50 ,env_size=20, dela=48)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "addfeature_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "addfeature_df.to_csv('1227_addfeature_df.csv',index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "addfeature_df = pd.read_csv('1227_addfeature_df.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df = pd.read_csv('1228_merged.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df['date'] = pd.to_datetime(merged_df['date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "addfeature_df['date'] = pd.to_datetime(addfeature_df['date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df1 = merged_df[['trade_date','ts_code','filled','ema']]\n",
    "merged_df1['date'] = pd.to_datetime(merged_df1['trade_date'])\n",
    "merged_df1['tic'] = merged_df1['ts_code']\n",
    "merged_df1 = merged_df1.loc[:,('date','tic','filled','ema')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "addfeature_df1 = pd.merge(addfeature_df,merged_df1,on=('date','tic'),how='left')\n",
    "addfeature_df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_df3.to_csv('1227_processed.csv',index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_df3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_df3 = pd.read_csv('1227_processed.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_df3['date'] = pd.to_datetime(processed_df3['date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "addfeature_df[addfeature_df['tic'] == '601939.SH']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.triu(g,diagonal=1+3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.triu(g,diagonal=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-QsYaY0Dh1iw"
   },
   "source": [
    "<a id='4'></a>\n",
    "# Part 5. Build A Market Environment in OpenAI Gym-style\n",
    "The training process involves observing stock price change, taking an action and reward's calculation. By interacting with the market environment, the agent will eventually derive a trading strategy that may maximize (expected) rewards.\n",
    "\n",
    "Our market environment, based on OpenAI Gym, simulates stock markets with historical market data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5TOhcryx44bb"
   },
   "source": [
    "## Data Split\n",
    "We split the data into training set and testing set as follows:\n",
    "\n",
    "Training data period: 2009-01-01 to 2020-07-01\n",
    "\n",
    "Trading data period: 2020-07-01 to 2021-10-31\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_START_DATE = '2015-03-02'\n",
    "TRAIN_END_DATE = '2020-07-30'\n",
    "TRADE_START_DATE = '2020-07-31'\n",
    "TRADE_END_DATE = '2021-02-26'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_START_DATE = addfeature_df['date'].unique()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "W0qaVGjLtgbI",
    "outputId": "ac9f2699-65c6-418f-cca4-f0f166973f65"
   },
   "outputs": [],
   "source": [
    "train = data_split(addfeature_df1, TRAIN_START_DATE,TRAIN_END_DATE)\n",
    "trade = data_split(addfeature_df1, TRADE_START_DATE,TRADE_END_DATE)\n",
    "print(len(train))\n",
    "print(len(trade))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "addfeature_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 357
    },
    "id": "p52zNCOhTtLR",
    "outputId": "14568787-e92d-4d9b-dbce-9e11b3fb1390"
   },
   "outputs": [],
   "source": [
    "train.tail(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "selfattn_indicator_list = [f\"temporal_feature_{i}\" for i in range(20)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "selfattn_indicator_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 357
    },
    "id": "k9zU9YaTTvFq",
    "outputId": "80e64947-4c5c-428f-a98c-6b344d816783"
   },
   "outputs": [],
   "source": [
    "trade.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "zYN573SOHhxG",
    "outputId": "460cd177-65d2-46f8-eb40-eaeda045c4bb"
   },
   "outputs": [],
   "source": [
    "INDICATORS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# stock_dimension = len(train.tic.unique())\n",
    "# state_space = 1 + 2*stock_dimension + len(selfattn_indicator_list)*stock_dimension\n",
    "# print(f\"Stock Dimension: {stock_dimension}, State Space: {state_space}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Q2zqII8rMIqn",
    "outputId": "d2e2b678-04f8-44be-96ea-3523903780eb"
   },
   "outputs": [],
   "source": [
    "stock_dimension = len(train.tic.unique())\n",
    "state_space = 1 + 4*stock_dimension + len(INDICATORS)*stock_dimension + len(selfattn_indicator_list)*stock_dimension\n",
    "print(f\"Stock Dimension: {stock_dimension}, State Space: {state_space}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "AWyp84Ltto19"
   },
   "outputs": [],
   "source": [
    "buy_cost_list = sell_cost_list = [0.001] * stock_dimension\n",
    "num_stock_shares = [0] * stock_dimension\n",
    "\n",
    "env_kwargs = {\n",
    "    \"hmax\": 500,\n",
    "    \"initial_amount\": 1000000,\n",
    "    \"num_stock_shares\": num_stock_shares,\n",
    "    \"buy_cost_pct\": buy_cost_list,\n",
    "    \"sell_cost_pct\": sell_cost_list,\n",
    "    \"state_space\": state_space,\n",
    "    \"stock_dim\": stock_dimension,\n",
    "    \"tech_indicator_list\": INDICATORS,\n",
    "    \"action_space\": stock_dimension,\n",
    "    \"risk_preference\": 'ne',   #ne为中性、pr为激进,除此之外都是保守策略\n",
    "    'adjust': True,  #True为启用动态调整机制，False关闭\n",
    "    \"reward_scaling\": 1,\n",
    "    \"attn_indicator_list\":selfattn_indicator_list,\n",
    "    \"alpha\": 100, #风险喜好函数系数\n",
    "    \"beta\" : 100, #风险中性函数系数\n",
    "    \"c\" : 100, # 风险厌恶函数系数\n",
    "    \"theta\" : 0.2, # 风险喜好放缩因子\n",
    "    \"gamma\" : 5, # 风险厌恶放缩因子\n",
    "    \"mu\" : 1, #惩罚项放缩因子\n",
    "    \"p_lambda\" : 100,  #惩罚系数\n",
    "    'up_ad_thre': 0.15, #动态调整机制中向上变化率阈值\n",
    "    'down_ad_thre': 0.1,  #动态调整机制中向下变化率阈值\n",
    "    \n",
    "}\n",
    "\n",
    "\n",
    "e_train_gym = StockTradingEnv(df = train, **env_kwargs)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "64EoqOrQjiVf"
   },
   "source": [
    "## Environment for Training\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "xwSvvPjutpqS",
    "outputId": "3645668e-ba1f-4610-9789-bc212eb9b776"
   },
   "outputs": [],
   "source": [
    "env_train, _ = e_train_gym.get_sb_env()\n",
    "print(type(env_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HMNR5nHjh1iz"
   },
   "source": [
    "<a id='5'></a>\n",
    "# Part 6: Train DRL Agents\n",
    "* The DRL algorithms are from **Stable Baselines 3**. Users are also encouraged to try **ElegantRL** and **Ray RLlib**.\n",
    "* FinRL includes fine-tuned standard DRL algorithms, such as DQN, DDPG, Multi-Agent DDPG, PPO, SAC, A2C and TD3. We also allow users to\n",
    "design their own DRL algorithms by adapting these DRL algorithms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "364PsqckttcQ"
   },
   "outputs": [],
   "source": [
    "agent = DRLAgent(env = env_train)\n",
    "\n",
    "if_using_a2c = False\n",
    "if_using_ddpg = False\n",
    "if_using_ppo = False\n",
    "if_using_td3 = True\n",
    "if_using_sac = False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "device = torch.device(\"mps\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YDmqOyF9h1iz"
   },
   "source": [
    "### Agent Training: 5 algorithms (A2C, DDPG, PPO, TD3, SAC)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uijiWgkuh1jB"
   },
   "source": [
    "### Agent 1: A2C\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "GUCnkn-HIbmj",
    "outputId": "a2bdd15c-c366-4f89-e6de-6b0572c2ad23"
   },
   "outputs": [],
   "source": [
    "agent = DRLAgent(env = env_train)\n",
    "model_a2c = agent.get_model(\"a2c\")\n",
    "\n",
    "if if_using_a2c:\n",
    "  # set up logger\n",
    "  tmp_path = RESULTS_DIR + '/a2c'\n",
    "  new_logger_a2c = configure(tmp_path, [\"stdout\", \"csv\", \"tensorboard\"])\n",
    "  # Set new logger\n",
    "  model_a2c.set_logger(new_logger_a2c)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0GVpkWGqH4-D"
   },
   "outputs": [],
   "source": [
    "trained_a2c = agent.train_model(model=model_a2c, \n",
    "                             tb_log_name='a2c',\n",
    "                             total_timesteps=50000) if if_using_a2c else None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MRiOtrywfAo1"
   },
   "source": [
    "### Agent 2: DDPG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "M2YadjfnLwgt",
    "outputId": "211f6ae4-c91e-41df-8906-df246e090f75"
   },
   "outputs": [],
   "source": [
    "agent = DRLAgent(env = env_train)\n",
    "model_ddpg = agent.get_model(\"ddpg\")\n",
    "\n",
    "if if_using_ddpg:\n",
    "  # set up logger\n",
    "  tmp_path = RESULTS_DIR + '/ddpg'\n",
    "  new_logger_ddpg = configure(tmp_path, [\"stdout\", \"csv\", \"tensorboard\"])\n",
    "  # Set new logger\n",
    "  model_ddpg.set_logger(new_logger_ddpg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "tCDa78rqfO_a"
   },
   "outputs": [],
   "source": [
    "trained_ddpg = agent.train_model(model=model_ddpg, \n",
    "                             tb_log_name='ddpg',\n",
    "                             total_timesteps=50000) if if_using_ddpg else None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_gDkU-j-fCmZ"
   },
   "source": [
    "### Agent 3: PPO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "y5D5PFUhMzSV",
    "outputId": "3405d353-0a08-4855-ca59-98098968dd11"
   },
   "outputs": [],
   "source": [
    "agent = DRLAgent(env = env_train)\n",
    "PPO_PARAMS = {\n",
    "    \"n_steps\": 2048,\n",
    "    \"ent_coef\": 0.01,\n",
    "    \"learning_rate\": 0.00025,\n",
    "    \"batch_size\": 128,\n",
    "}\n",
    "model_ppo = agent.get_model(\"ppo\",model_kwargs = PPO_PARAMS)\n",
    "\n",
    "if if_using_ppo:\n",
    "  # set up logger\n",
    "  tmp_path = RESULTS_DIR + '/ppo'\n",
    "  new_logger_ppo = configure(tmp_path, [\"stdout\", \"csv\", \"tensorboard\"])\n",
    "  # Set new logger\n",
    "  model_ppo.set_logger(new_logger_ppo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Gt8eIQKYM4G3",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "trained_ppo = agent.train_model(model=model_ppo, \n",
    "                             tb_log_name='ppo',\n",
    "                             total_timesteps=30000) if if_using_ppo else None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3Zpv4S0-fDBv"
   },
   "source": [
    "### Agent 4: TD3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "JSAHhV4Xc-bh",
    "outputId": "802fef04-8df5-4df2-f710-e5b08941842f"
   },
   "outputs": [],
   "source": [
    "agent = DRLAgent(env = env_train)\n",
    "TD3_PARAMS = {\"batch_size\": 100, \n",
    "              \"buffer_size\": 1000000, \n",
    "              \"learning_rate\": 0.001}\n",
    "\n",
    "model_td3 = agent.get_model(\"td3\",model_kwargs = TD3_PARAMS)\n",
    "\n",
    "if if_using_td3:\n",
    "  # set up logger\n",
    "  tmp_path = RESULTS_DIR + '/td3'\n",
    "  new_logger_td3 = configure(tmp_path, [\"stdout\", \"csv\", \"tensorboard\"])\n",
    "  # Set new logger\n",
    "  model_td3.set_logger(new_logger_td3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "OSRxNYAxdKpU"
   },
   "outputs": [],
   "source": [
    "trained_td3 = agent.train_model(model=model_td3, \n",
    "                             tb_log_name='td3',\n",
    "                             total_timesteps=30000) if if_using_td3 else None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Dr49PotrfG01"
   },
   "source": [
    "### Agent 5: SAC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "xwOhVjqRkCdM",
    "outputId": "3c848ff6-587e-43d1-b50d-a7d521a14b4f",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "agent = DRLAgent(env = env_train)\n",
    "SAC_PARAMS = {\n",
    "    \"batch_size\": 128,\n",
    "    \"buffer_size\": 100000,\n",
    "    \"learning_rate\": 0.0001,\n",
    "    \"learning_starts\": 100,\n",
    "    \"ent_coef\": \"auto_0.1\",\n",
    "}\n",
    "\n",
    "model_sac = agent.get_model(\"sac\",model_kwargs = SAC_PARAMS)\n",
    "\n",
    "if if_using_sac:\n",
    "  # set up logger\n",
    "  tmp_path = RESULTS_DIR + '/sac'\n",
    "  new_logger_sac = configure(tmp_path, [\"stdout\", \"csv\", \"tensorboard\"])\n",
    "  # Set new logger\n",
    "  model_sac.set_logger(new_logger_sac)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "K8RSdKCckJyH",
    "outputId": "4d65a11b-32b0-4c3f-b0da-e1b59fc6e194",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "trained_sac = agent.train_model(model=model_sac, \n",
    "                             tb_log_name='sac',\n",
    "                             total_timesteps=30000) if if_using_sac else None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "f2wZgkQXh1jE"
   },
   "source": [
    "## In-sample Performance\n",
    "\n",
    "Assume that the initial capital is $1,000,000."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bEv5KGC8h1jE"
   },
   "source": [
    "### Set turbulence threshold\n",
    "Set the turbulence threshold to be greater than the maximum of insample turbulence data. If current turbulence index is greater than the threshold, then we assume that the current market is volatile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "efwBi84ch1jE"
   },
   "outputs": [],
   "source": [
    "data_risk_indicator = addfeature_df[(addfeature_df.date<TRAIN_END_DATE) & (addfeature_df.date>=TRAIN_START_DATE)]\n",
    "insample_risk_indicator = data_risk_indicator.drop_duplicates(subset=['date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "VHZMBpSqh1jG",
    "outputId": "73edde3b-1414-4a0d-f876-6460de2ff8e1"
   },
   "outputs": [],
   "source": [
    "insample_risk_indicator.vix.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "BDkszkMloRWT",
    "outputId": "c5df1f2f-ed52-4107-a3af-a358767ae155"
   },
   "outputs": [],
   "source": [
    "insample_risk_indicator.vix.quantile(0.996)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "AL7hs7svnNWT",
    "outputId": "ab5a1015-3f83-41b7-ba65-1487f3188588"
   },
   "outputs": [],
   "source": [
    "insample_risk_indicator.turbulence.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "N78hfHckoqJ9",
    "outputId": "2c8a54d6-022f-4716-dc6d-22a450f5b9ab"
   },
   "outputs": [],
   "source": [
    "insample_risk_indicator.turbulence.quantile(0.996)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "U5mmgQF_h1jQ"
   },
   "source": [
    "### Trading (Out-of-sample Performance)\n",
    "\n",
    "We update periodically in order to take full advantage of the data, e.g., retrain quarterly, monthly or weekly. We also tune the parameters along the way, in this notebook we use the in-sample data from 2009-01 to 2020-07 to tune the parameters once, so there is some alpha decay here as the length of trade date extends. \n",
    "\n",
    "Numerous hyperparameters – e.g. the learning rate, the total number of samples to train on – influence the learning process and are usually determined by testing some variations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cIqoV0GSI52v"
   },
   "outputs": [],
   "source": [
    "e_trade_gym = StockTradingEnv(df = trade,**env_kwargs)\n",
    "# env_trade, obs_trade = e_trade_gym.get_sb_env()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 357
    },
    "id": "W_XNgGsBMeVw",
    "outputId": "56d2af8e-7ee7-4248-ce7a-3132625c61b1"
   },
   "outputs": [],
   "source": [
    "trade.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "eLOnL5eYh1jR",
    "outputId": "d31d2209-05ef-41df-fd8f-ee081d427949"
   },
   "outputs": [],
   "source": [
    "trained_moedl = trained_td3\n",
    "df_account_value, df_actions = DRLAgent.DRL_prediction(\n",
    "    model=trained_moedl, \n",
    "    environment = e_trade_gym)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_account_value.to_csv('107_up_up_df_account_value.csv',index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ERxw3KqLkcP4",
    "outputId": "780c7269-0139-42e0-8ad6-081fd93717bf"
   },
   "outputs": [],
   "source": [
    "df_account_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "2yRkNguY5yvp",
    "outputId": "13f1ace3-c343-4bee-e0c1-214b2f8a1372"
   },
   "outputs": [],
   "source": [
    "df_account_value.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 267
    },
    "id": "nFlK5hNbWVFk",
    "outputId": "a635843e-7732-47ce-8044-9c87a33de736"
   },
   "outputs": [],
   "source": [
    "df_actions.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "W6vvNSC6h1jZ"
   },
   "source": [
    "<a id='6'></a>\n",
    "# Part 7: Backtesting Results\n",
    "Backtesting plays a key role in evaluating the performance of a trading strategy. Automated backtesting tool is preferred because it reduces the human error. We usually use the Quantopian pyfolio package to backtest our trading strategies. It is easy to use and consists of various individual plots that provide a comprehensive image of the performance of a trading strategy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Lr2zX7ZxNyFQ"
   },
   "source": [
    "<a id='6.1'></a>\n",
    "## 7.1 BackTestStats\n",
    "pass in df_account_value, this information is stored in env class\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Nzkr9yv-AdV_",
    "outputId": "216032a2-5566-4dba-db83-7d7d880b1e88"
   },
   "outputs": [],
   "source": [
    "print(\"==============Get Backtest Results===========\")\n",
    "#now = datetime.datetime.now().strftime('%Y%m%d-%Hh%M')\n",
    "\n",
    "perf_stats_all = backtest_stats(account_value=df_account_value)\n",
    "perf_stats_all = pd.DataFrame(perf_stats_all)\n",
    "#perf_stats_all.to_csv(\"./\"+RESULTS_DIR+\"/perf_stats_all_\"+now+'.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"==============Get Backtest Results===========\")\n",
    "#now = datetime.datetime.now().strftime('%Y%m%d-%Hh%M')\n",
    "\n",
    "perf_stats_all = backtest_stats(account_value=df_account_value)\n",
    "perf_stats_all = pd.DataFrame(perf_stats_all)\n",
    "#perf_stats_all.to_csv(\"./\"+RESULTS_DIR+\"/perf_stats_all_\"+now+'.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"==============Get Backtest Results===========\")\n",
    "#now = datetime.datetime.now().strftime('%Y%m%d-%Hh%M')\n",
    "\n",
    "perf_stats_all = backtest_stats(account_value=df_account_value)\n",
    "perf_stats_all = pd.DataFrame(perf_stats_all)\n",
    "#perf_stats_all.to_csv(\"./\"+RESULTS_DIR+\"/perf_stats_all_\"+now+'.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#获取随机选择的tic在select_date的权重并修正\n",
    "def get_selected_index_weight(df_index,select_date,selected_tics):\n",
    "    df = df_index[df_index['trade_date'] == select_date]\n",
    "    select_df = df[df['con_code'].isin(selected_tics)]\n",
    "    select_df = select_df.drop('index_code',axis=1).rename(columns={'con_code':'tic','trade_date':'date'})\n",
    "    select_df = select_df.reset_index()\n",
    "    weight_sum = select_df['weight'].sum()\n",
    "#     print(select_df)\n",
    "    for i in range(len(select_df)):\n",
    "        select_df.loc[i,'weight'] = (select_df.loc[i,'weight'] / weight_sum)*100\n",
    "    return select_df.loc[:,['tic','date','weight']]\n",
    "\n",
    "baseline_weight =get_selected_index_weight(df_index,select_date,selected_tics)\n",
    "baseline_weight = baseline_weight.sort_values(['tic'],ascending=True).reset_index(drop=True)\n",
    "print(baseline_weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#计算所选股票的buy & hold策略\n",
    "def calculate_selected_baseline(df,full_date_range,selected_tics):\n",
    "    df = df.sort_values(['tic','date'],ascending=True).reset_index(drop=True)\n",
    "    baseline = pd.DataFrame({'date':full_date_range['date']})\n",
    "    for i in range(len(full_date_range)):\n",
    "        temp_date = full_date_range.loc[i,'date']\n",
    "        temp_df = df[df['date'] == temp_date].sort_values('tic',ascending=True)\n",
    "        close = list(temp_df['close'])\n",
    "        weight = list(baseline_weight['weight'])\n",
    "        baseline.loc[i,'account_value'] = sum(np.array(close) * np.array(weight)) #注意权重和收盘价对应的股票顺序\n",
    "    baseline['date'] = pd.to_datetime(baseline['date'],format='%Y%m%d')\n",
    "#     baseline.set_index(\"date\", inplace=True, drop=True)\n",
    "#     baseline.index = baseline.index.tz_localize(\"UTC\")\n",
    "    return baseline\n",
    "# full_date_range = get_trading_days(exchange='SSE',start_date='20210301', end_date='20230227')\n",
    "# full_date_range = full_date_range.sort_values('trade_date',ascending=True).reset_index(drop=True)\n",
    "# subset_df = addfeature_df.loc[(addfeature_df['date'].astype(str) >='20210301') & (addfeature_df['date'].astype(str)<='20220227')]\n",
    "full_date_range1 = pd.DataFrame({'date':df_account_value['date'].unique()}).reset_index(drop=True)\n",
    "baseline_sse = calculate_selected_baseline(addfeature_df,full_date_range1,selected_tics)\n",
    "baseline_sse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "addfeature_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "baseline_sse.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# baseline_sse = pro.index_daily(ts_code='000016.sh',start_date = '20200301',end_date='20230227')\n",
    "# baseline_sse = baseline_sse.rename(columns={'trade_date':'date'})\n",
    "# baseline_sse = baseline_sse.sort_values('date',ascending=True)\n",
    "# print(baseline_sse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "QkV-LB66iwhD",
    "outputId": "7231e720-1598-45ac-ff49-9f8d29f296fa"
   },
   "outputs": [],
   "source": [
    "#baseline stats\n",
    "print(\"==============Get Baseline Stats===========\")\n",
    "# baseline_df = get_baseline(\n",
    "#         ticker=\"^DJI\", \n",
    "#         start = df_account_value.loc[0,'date'],\n",
    "#         end = df_account_value.loc[len(df_account_value)-1,'date'])\n",
    "\n",
    "stats = backtest_stats(baseline_sse, value_col_name = 'account_value')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_account_value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9U6Suru3h1jc"
   },
   "source": [
    "<a id='6.2'></a>\n",
    "## 7.2 BackTestPlot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyfolio\n",
    "from copy import deepcopy\n",
    "def backtest_plot_com(\n",
    "    account_value,\n",
    "    baseline,\n",
    "    baseline_start=TRADE_START_DATE,\n",
    "    baseline_end=TRADE_END_DATE,\n",
    "    value_col_name=\"account_value\",\n",
    "):\n",
    "    df = deepcopy(account_value)\n",
    "    df[\"date\"] = pd.to_datetime(df[\"date\"])\n",
    "    test_returns = get_daily_return(df, value_col_name=value_col_name)\n",
    "#     pro = ts.pro_api()\n",
    "#     baseline_df = pro.index_daily(ts_code='000016.sh',start_date = '20200301',end_date='20230227')\n",
    "#     baseline_df = baseline_df.rename(columns={'trade_date':'date'})\n",
    "#     baseline_df = baseline_df.sort_values('date',ascending=True)\n",
    "    baseline_returns = get_daily_return(baseline, value_col_name=value_col_name)\n",
    "    with pyfolio.plotting.plotting_context(font_scale=1.1):\n",
    "        pyfolio.create_full_tear_sheet(\n",
    "            returns=test_returns, benchmark_rets=baseline_returns, set_context=False\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(\"==============Compare to SSE50===========\")\n",
    "# from finrl.plot import backtest_plot_com\n",
    "%matplotlib inline\n",
    "# S&P 500: ^GSPC\n",
    "# Dow Jones Index: ^DJI\n",
    "# NASDAQ 100: ^NDX\n",
    "backtest_plot_com(account_value = df_account_value, \n",
    "                  baseline = baseline_sse,\n",
    "                  baseline_start = df_account_value.loc[len(df_account_value)-1,'date'],\n",
    "                  baseline_end = df_account_value.loc[0,'date']\n",
    "                     )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "lKRGftSS7pNM",
    "outputId": "db260938-69a7-4417-fed7-25679d43b0f6"
   },
   "outputs": [],
   "source": [
    "print(\"==============Compare to SSE50===========\")\n",
    "# from finrl.plot import backtest_plot_com\n",
    "%matplotlib inline\n",
    "# S&P 500: ^GSPC\n",
    "# Dow Jones Index: ^DJI\n",
    "# NASDAQ 100: ^NDX\n",
    "backtest_plot_com(account_value = df_account_value, \n",
    "                  baseline = baseline_sse,\n",
    "                  baseline_start = df_account_value.loc[len(df_account_value)-1,'date'],\n",
    "                  baseline_end = df_account_value.loc[0,'date']\n",
    "                     )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"==============Compare to SSE50===========\")\n",
    "# from finrl.plot import backtest_plot_com\n",
    "%matplotlib inline\n",
    "# S&P 500: ^GSPC\n",
    "# Dow Jones Index: ^DJI\n",
    "# NASDAQ 100: ^NDX\n",
    "backtest_plot_com(account_value = df_account_value, \n",
    "                  baseline = baseline_sse,\n",
    "                  baseline_start = df_account_value.loc[len(df_account_value)-1,'date'],\n",
    "                  baseline_end = df_account_value.loc[0,'date']\n",
    "                     )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df_account_value.loc[len(df_account_value)-1,'date'],df_account_value.loc[0,'date'])"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "_gDkU-j-fCmZ",
    "3Zpv4S0-fDBv"
   ],
   "name": "Stock_NeurIPS2018.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
